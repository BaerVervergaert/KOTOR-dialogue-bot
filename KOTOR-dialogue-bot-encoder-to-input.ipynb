{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef69c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from math import ceil, floor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import time\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691d77dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Config settings\n",
    "\n",
    "## Data config\n",
    "# Download the data again regardless if it already exists?\n",
    "download_again = False\n",
    "\n",
    "\n",
    "## DataLoader config\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "## Model config\n",
    "# filenames for model storage\n",
    "encoder_name = 'kotor-rnn-encoder-encinput.ptm'\n",
    "decoder_name = 'kotor-rnn-decoder-encinput.ptm'\n",
    "# Scheduler rate {constant,sqrt,linear}\n",
    "scheduler_rate = 'sqrt'\n",
    "# Num of training epochs\n",
    "epochs = 1000\n",
    "\n",
    "# Load the stored model?\n",
    "load_model = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f55a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69224d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/hmi-utwente/video-game-text-corpora/raw/master/Star%20Wars:%20Knights%20of%20the%20Old%20Republic/data/dataset_20200716.csv'\n",
    "filename = 'dataset_20200716.csv'\n",
    "if (not os.path.exists(filename)) or download_again:\n",
    "    urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a2f005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>listener</th>\n",
       "      <th>text</th>\n",
       "      <th>animation</th>\n",
       "      <th>comment</th>\n",
       "      <th>next</th>\n",
       "      <th>previous</th>\n",
       "      <th>source_dlg</th>\n",
       "      <th>audiofile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anchorhead Tradesman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take care of yourself. The price of kolto tank...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>tat17_news_01</td>\n",
       "      <td>NM17AANEWS11000_.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anchorhead Tradesman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Selkath put a bunch of export restrictions...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>tat17_news_01</td>\n",
       "      <td>NM17AANEWS11001_.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anchorhead Tradesman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I hear that Manaan is no longer shipping kolto...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>tat17_news_01</td>\n",
       "      <td>NM17AANEWS11002_.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anchorhead Tradesman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you have kolto tanks, use them sparingly. I...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>tat17_news_01</td>\n",
       "      <td>NM17AANEWS11003_.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anchorhead Tradesman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm sure I saw some holo-footage of you on the...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[None]</td>\n",
       "      <td>tat17_news_01</td>\n",
       "      <td>NM17AANEWS11004_.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29208</th>\n",
       "      <td>Zaalbar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is a description of the ritual you have alr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[29207, 29211]</td>\n",
       "      <td>kas25_ritualmark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29209</th>\n",
       "      <td>Zaalbar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I never went to the Shadowlands to prove mysel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[29210]</td>\n",
       "      <td>[29207, 29211]</td>\n",
       "      <td>kas25_ritualmark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29210</th>\n",
       "      <td>Zaalbar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You will have to follow whatever your instinct...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[29209]</td>\n",
       "      <td>kas25_ritualmark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29211</th>\n",
       "      <td>Player</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whatever. Just tell me what you know about it.</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[29208, 29209]</td>\n",
       "      <td>[29206]</td>\n",
       "      <td>kas25_ritualmark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29212</th>\n",
       "      <td>Conversation owner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Obviously this was once a place of great ritu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[29205]</td>\n",
       "      <td>kas25_ritualmark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29213 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    speaker listener  \\\n",
       "id                                     \n",
       "0      Anchorhead Tradesman      NaN   \n",
       "1      Anchorhead Tradesman      NaN   \n",
       "2      Anchorhead Tradesman      NaN   \n",
       "3      Anchorhead Tradesman      NaN   \n",
       "4      Anchorhead Tradesman      NaN   \n",
       "...                     ...      ...   \n",
       "29208               Zaalbar      NaN   \n",
       "29209               Zaalbar      NaN   \n",
       "29210               Zaalbar      NaN   \n",
       "29211                Player      NaN   \n",
       "29212    Conversation owner      NaN   \n",
       "\n",
       "                                                    text animation comment  \\\n",
       "id                                                                           \n",
       "0      Take care of yourself. The price of kolto tank...        []     NaN   \n",
       "1      The Selkath put a bunch of export restrictions...        []     NaN   \n",
       "2      I hear that Manaan is no longer shipping kolto...        []     NaN   \n",
       "3      If you have kolto tanks, use them sparingly. I...        []     NaN   \n",
       "4      I'm sure I saw some holo-footage of you on the...        []     NaN   \n",
       "...                                                  ...       ...     ...   \n",
       "29208  It is a description of the ritual you have alr...        []     NaN   \n",
       "29209  I never went to the Shadowlands to prove mysel...        []     NaN   \n",
       "29210  You will have to follow whatever your instinct...        []     NaN   \n",
       "29211     Whatever. Just tell me what you know about it.        []     NaN   \n",
       "29212  [Obviously this was once a place of great ritu...        []     NaN   \n",
       "\n",
       "                 next        previous        source_dlg             audiofile  \n",
       "id                                                                             \n",
       "0                  []          [None]     tat17_news_01  NM17AANEWS11000_.mp3  \n",
       "1                  []          [None]     tat17_news_01  NM17AANEWS11001_.mp3  \n",
       "2                  []          [None]     tat17_news_01  NM17AANEWS11002_.mp3  \n",
       "3                  []          [None]     tat17_news_01  NM17AANEWS11003_.mp3  \n",
       "4                  []          [None]     tat17_news_01  NM17AANEWS11004_.mp3  \n",
       "...               ...             ...               ...                   ...  \n",
       "29208              []  [29207, 29211]  kas25_ritualmark                   NaN  \n",
       "29209         [29210]  [29207, 29211]  kas25_ritualmark                   NaN  \n",
       "29210              []         [29209]  kas25_ritualmark                   NaN  \n",
       "29211  [29208, 29209]         [29206]  kas25_ritualmark                   NaN  \n",
       "29212              []         [29205]  kas25_ritualmark                   NaN  \n",
       "\n",
       "[29213 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_col = 'id'\n",
    "usecols = None\n",
    "#usecols = ['id','text','previous']\n",
    "converters = {'previous':ast.literal_eval,\n",
    "              'next':ast.literal_eval,\n",
    "             }\n",
    "data = pd.read_csv(filename,\n",
    "                   index_col=index_col,\n",
    "                   usecols=usecols,\n",
    "                   converters=converters,\n",
    "                  )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60895540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker       object\n",
       "listener      object\n",
       "text          object\n",
       "animation     object\n",
       "comment       object\n",
       "next          object\n",
       "previous      object\n",
       "source_dlg    object\n",
       "audiofile     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7462385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29213 entries, 0 to 29212\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   speaker     29213 non-null  object\n",
      " 1   listener    2231 non-null   object\n",
      " 2   text        29213 non-null  object\n",
      " 3   animation   29213 non-null  object\n",
      " 4   comment     2658 non-null   object\n",
      " 5   next        29213 non-null  object\n",
      " 6   previous    29213 non-null  object\n",
      " 7   source_dlg  29213 non-null  object\n",
      " 8   audiofile   12325 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed7e886a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t speaker\n",
      "count    29213.000000\n",
      "mean         8.973094\n",
      "std          4.522340\n",
      "min          3.000000\n",
      "25%          6.000000\n",
      "50%          6.000000\n",
      "75%         12.000000\n",
      "max         24.000000\n",
      "Name: speaker, dtype: float64\n",
      "\n",
      "\t text\n",
      "count    29213.000000\n",
      "mean        82.780748\n",
      "std         49.850241\n",
      "min          1.000000\n",
      "25%         39.000000\n",
      "50%         74.000000\n",
      "75%        122.000000\n",
      "max        344.000000\n",
      "Name: text, dtype: float64\n",
      "\n",
      "\t animation\n",
      "count    29213.000000\n",
      "mean         4.144867\n",
      "std          8.150476\n",
      "min          2.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          2.000000\n",
      "max        243.000000\n",
      "Name: animation, dtype: float64\n",
      "\n",
      "\t next\n",
      "count    29213.000000\n",
      "mean         1.498100\n",
      "std          1.451002\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          2.000000\n",
      "max         22.000000\n",
      "Name: next, dtype: float64\n",
      "\n",
      "\t previous\n",
      "count    29213.000000\n",
      "mean         1.611235\n",
      "std          1.664769\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max         34.000000\n",
      "Name: previous, dtype: float64\n",
      "\n",
      "\t source_dlg\n",
      "count    29213.000000\n",
      "mean        13.488344\n",
      "std          1.975279\n",
      "min          2.000000\n",
      "25%         12.000000\n",
      "50%         13.000000\n",
      "75%         15.000000\n",
      "max         16.000000\n",
      "Name: source_dlg, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    try:\n",
    "        desc = data[col].apply(len).describe()\n",
    "        print('\\t',col)\n",
    "        print(desc)\n",
    "        print()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fae13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start_stop_codon(data,column,start='\\r',stop='\\n',force=False):\n",
    "    detect_start_stop = lambda s,start=start,stop=stop: start in s or stop in s\n",
    "    codons_in_text = data[column].apply(detect_start_stop).any()\n",
    "    if codons_in_text:\n",
    "        if not force:\n",
    "            raise ValueError('data already contains start or stop codon at column: {0}'.format(column))\n",
    "    transform = lambda s,start=start,stop=stop: start+s+stop\n",
    "    data[column] = data[column].apply(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c48f28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0        \\rTake care of yourself. The price of kolto ta...\n",
       "1        \\rThe Selkath put a bunch of export restrictio...\n",
       "2        \\rI hear that Manaan is no longer shipping kol...\n",
       "3        \\rIf you have kolto tanks, use them sparingly....\n",
       "4        \\rI'm sure I saw some holo-footage of you on t...\n",
       "                               ...                        \n",
       "29208    \\rIt is a description of the ritual you have a...\n",
       "29209    \\rI never went to the Shadowlands to prove mys...\n",
       "29210    \\rYou will have to follow whatever your instin...\n",
       "29211    \\rWhatever. Just tell me what you know about i...\n",
       "29212    \\r[Obviously this was once a place of great ri...\n",
       "Name: text, Length: 29213, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_start_stop_codon(data,'text')\n",
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd27d21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.tensors = {}\n",
    "        \n",
    "        #Make Vocab\n",
    "        self.vocab = sorted(list(set(''.join(self.data['text']))))\n",
    "        self.ch2i = { v:k for k,v in enumerate(self.vocab) }\n",
    "        self.i2ch = { v:k for k,v in self.ch2i.items() }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.data))\n",
    "    def str2vec(self,text):\n",
    "        out = torch.tensor([ self.ch2i[s] for s in text],dtype=torch.long)\n",
    "        return(out)\n",
    "    def vec2str(self,vec):\n",
    "        out = ''.join([ self.i2ch[i.item()] for i in vec ])\n",
    "        return(out)\n",
    "    def get_dialogue(self,idx):\n",
    "        try:\n",
    "            dialogue = self.tensors[idx]\n",
    "        except:\n",
    "            if idx is None:\n",
    "                dialogue = '\\r\\n'\n",
    "            else:\n",
    "                dialogue = self.data.loc[idx,'text']\n",
    "            dialogue = self.str2vec(dialogue)\n",
    "            self.tensors[idx] = dialogue\n",
    "        return(dialogue)\n",
    "    def __getitem__(self,idx):\n",
    "        self.data.loc[idx,'text']\n",
    "        response = self.get_dialogue(idx)\n",
    "        ins = response[:-1]\n",
    "        outs = response[1:]\n",
    "        prevs = self.data.loc[idx,'previous']\n",
    "        prevs = np.random.choice(prevs)\n",
    "        prevs = self.get_dialogue(prevs)\n",
    "        return(prevs,ins,outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bfcb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29213\n",
      "\n",
      "['\\n', '\\r', ' ', '!', '\"', '#', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "(tensor([1, 0]), tensor([ 1, 53, 64, 74, 68,  2, 66, 64, 81, 68,  2, 78, 69,  2, 88, 78, 84, 81,\n",
      "        82, 68, 75, 69, 15,  2, 53, 71, 68,  2, 79, 81, 72, 66, 68,  2, 78, 69,\n",
      "         2, 74, 78, 75, 83, 78,  2, 83, 64, 77, 74, 82,  2, 71, 64, 82,  2, 73,\n",
      "        84, 76, 79, 68, 67,  2, 83, 71, 81, 78, 84, 70, 71,  2, 83, 71, 68,  2,\n",
      "        81, 78, 78, 69, 15]), tensor([53, 64, 74, 68,  2, 66, 64, 81, 68,  2, 78, 69,  2, 88, 78, 84, 81, 82,\n",
      "        68, 75, 69, 15,  2, 53, 71, 68,  2, 79, 81, 72, 66, 68,  2, 78, 69,  2,\n",
      "        74, 78, 75, 83, 78,  2, 83, 64, 77, 74, 82,  2, 71, 64, 82,  2, 73, 84,\n",
      "        76, 79, 68, 67,  2, 83, 71, 81, 78, 84, 70, 71,  2, 83, 71, 68,  2, 81,\n",
      "        78, 78, 69, 15,  0]))\n",
      "\n",
      "(tensor([ 1, 60, 39, 68, 68, 67,  2, 83, 71, 68,  2, 65, 68, 64, 82, 83,  2, 64,\n",
      "        77, 67,  2, 72, 83,  2, 86, 72, 75, 75,  2, 71, 68, 68, 67,  2, 88, 78,\n",
      "        84, 81,  2, 66, 64, 75, 75, 15,  2, 53, 64, 74, 68,  2, 85, 72, 79, 68,\n",
      "        81, 82,  2, 69, 81, 78, 76,  2, 83, 71, 68, 72, 81,  2, 75, 64, 72, 81,\n",
      "         2, 64, 77, 67,  2, 71, 64, 77, 70,  2, 83, 71, 68, 76,  2, 69, 81, 78,\n",
      "        76,  2, 64, 65, 78, 85, 68, 15,  2, 45, 68, 83,  2, 65, 75, 78, 78, 67,\n",
      "         2, 82, 66, 68, 77, 83,  2, 83, 71, 68,  2, 70, 81, 78, 84, 77, 67,  2,\n",
      "        78, 69,  2, 78, 84, 81,  2, 64, 77, 66, 68, 82, 83, 78, 81, 82, 15, 61,\n",
      "         0]), tensor([ 1, 60, 48, 65, 85, 72, 78, 84, 82, 75, 88,  2, 83, 71, 72, 82,  2, 86,\n",
      "        64, 82,  2, 78, 77, 66, 68,  2, 64,  2, 79, 75, 64, 66, 68,  2, 78, 69,\n",
      "         2, 70, 81, 68, 64, 83,  2, 81, 72, 83, 84, 64, 75,  2, 72, 76, 79, 78,\n",
      "        81, 83, 64, 77, 66, 68, 15, 61]), tensor([60, 48, 65, 85, 72, 78, 84, 82, 75, 88,  2, 83, 71, 72, 82,  2, 86, 64,\n",
      "        82,  2, 78, 77, 66, 68,  2, 64,  2, 79, 75, 64, 66, 68,  2, 78, 69,  2,\n",
      "        70, 81, 68, 64, 83,  2, 81, 72, 83, 84, 64, 75,  2, 72, 76, 79, 78, 81,\n",
      "        83, 64, 77, 66, 68, 15, 61,  0]))\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(data)\n",
    "print(len(dataset))\n",
    "print()\n",
    "print(dataset.vocab)\n",
    "print()\n",
    "print(dataset[0])\n",
    "print()\n",
    "print(dataset[len(dataset)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f9c57d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data_points):\n",
    "    L_prevs = [len(p) for p,i,o in data_points]\n",
    "    L_currents  = [len(i) for p,i,o in data_points]\n",
    "    N_prevs = max(*L_prevs)\n",
    "    N_currents = max(*L_currents)\n",
    "    B = len(data_points)\n",
    "    prevs = torch.zeros((B,N_prevs),dtype=data_points[0][0].dtype)\n",
    "    ins = torch.zeros((B,N_currents),dtype=data_points[0][1].dtype)\n",
    "    outs = torch.zeros((B,N_currents),dtype=data_points[0][2].dtype)\n",
    "    for k in range(B):\n",
    "        l_prevs = L_prevs[k]\n",
    "        prevs[k,:l_prevs] = data_points[k][0]\n",
    "        l_currents = L_currents[k]\n",
    "        ins[k,:l_currents] = data_points[k][1]\n",
    "        outs[k,:l_currents] = data_points[k][2]\n",
    "    return((prevs,ins,outs),L_prevs,L_currents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0c6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True,\n",
    "                                         pin_memory=True,\n",
    "                                         collate_fn=collate_fn,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49fcf15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainablePositionalEncoding(nn.Module):\n",
    "    def __init__(self,encoding_dim,num_of_features=None):\n",
    "        super(TrainablePositionalEncoding,self).__init__()\n",
    "        self.num_of_features = num_of_features\n",
    "        self.encoding_dim = encoding_dim\n",
    "        if encoding_dim%2!=0:\n",
    "            raise ValueError('encoding_dim should be a multiple of two!')\n",
    "        if num_of_features is None:\n",
    "            self.exp_linear = nn.Linear(1,encoding_dim//2,bias=True)\n",
    "            self.angle_linear = nn.Linear(1,encoding_dim//2,bias=False)\n",
    "        else:\n",
    "            self.exp_linear = nn.Linear(self.num_of_features,encoding_dim//2,bias=True)\n",
    "            self.angle_linear = nn.Linear(self.num_of_features,encoding_dim//2,bias=True)\n",
    "    def forward(self,x):\n",
    "        if self.num_of_features is None:\n",
    "            x = x.unsqueeze(-1)\n",
    "        exp_tensor = torch.exp(self.exp_linear(x)/80)\n",
    "        angle_tensor = self.angle_linear(x)\n",
    "        out = torch.cat((exp_tensor*torch.sin(angle_tensor),exp_tensor*torch.cos(angle_tensor)),dim=-1)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d78f2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_positional_info(x,ch2i = dataset.ch2i):\n",
    "    try:\n",
    "        space_idx = add_positional_info.space_idx\n",
    "        punct_idx = add_positional_info.punct_idx\n",
    "    except AttributeError:\n",
    "        space_idx = ch2i[' ']\n",
    "        punct_idx = torch.tensor([ ch2i[s] for s in ['.','!','?'] ]).to(device)\n",
    "        add_positional_info.space_idx = space_idx\n",
    "        add_positional_info.punct_idx = punct_idx\n",
    "    punct_mask = torch.isin(x,punct_idx)\n",
    "    punct_mask = punct_mask.cumsum(axis=1)\n",
    "    space_mask = x==space_idx\n",
    "    out = 0\n",
    "    try:\n",
    "        punct_mask_max = punct_mask.max().item()\n",
    "    except RuntimeError:\n",
    "        punct_mask_max = 0\n",
    "    for punct_mark in range(punct_mask_max+1):\n",
    "        punct_mark_mask = (punct_mask==punct_mark)\n",
    "        out += (space_mask*punct_mark_mask).cumsum(axis=1)*punct_mark_mask\n",
    "    out = torch.stack((x,out),dim=2)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b1dc7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, out_dim, embedding_dim, rnn_units, n_layers=2):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn_units = rnn_units\n",
    "        self.out_dim = out_dim\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                     )\n",
    "        self.pos_encoding = TrainablePositionalEncoding(embedding_dim)\n",
    "        self.grus = nn.ModuleList()\n",
    "        self.linears = nn.ModuleList()\n",
    "        self.initial_states = nn.ParameterList()\n",
    "        for submodel_layers in range(1,n_layers+1):\n",
    "            submodel_gru = nn.GRU(input_size=embedding_dim,\n",
    "                                          hidden_size=self.rnn_units,\n",
    "                                          num_layers=submodel_layers,\n",
    "                                          batch_first=True,\n",
    "                                         )\n",
    "            submodel_linear = nn.Linear(rnn_units,\n",
    "                                                out_dim,\n",
    "                                                bias=True,\n",
    "                                               )\n",
    "            self.grus.append(submodel_gru)\n",
    "            self.linears.append(submodel_linear)\n",
    "            self.initial_states.append(nn.Parameter(torch.randn((submodel_layers,self.rnn_units,))))\n",
    "        self.bias = nn.Parameter(torch.randn((out_dim,)))\n",
    "    def batch_initial_states(self,batch_size):\n",
    "        states = [ init_state.repeat((batch_size,1,1)).permute(1,0,2) for init_state in self.initial_states ]\n",
    "        return(states)\n",
    "    def forward(self, inputs, lengths, states=None,device=device):\n",
    "        batch_size = len(lengths)\n",
    "        if states is None:\n",
    "            states = self.batch_initial_states(batch_size)\n",
    "        x = self.embedding(inputs[...,0])\n",
    "        x += self.pos_encoding(inputs[...,1].float())\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x,lengths,batch_first=True,enforce_sorted=False)\n",
    "        out = 0\n",
    "        for k in range(len(self.grus)):\n",
    "            # Apply GRU\n",
    "            state = states[k]\n",
    "            submodel_gru = self.grus[k]\n",
    "            sub_out, state = submodel_gru(x,state)\n",
    "\n",
    "            # Apply linear transform\n",
    "            sub_out,_ = torch.nn.utils.rnn.pad_packed_sequence(sub_out, batch_first=True)\n",
    "            sub_out = sub_out[torch.arange(len(lengths)),torch.tensor(lengths).to(device)-1]\n",
    "            submodel_linear = self.linears[k]\n",
    "            sub_out = submodel_linear(sub_out)\n",
    "            \n",
    "            # Collect in output\n",
    "            out += sub_out\n",
    "        return(out)\n",
    "    def noisify(self,scale):\n",
    "        with torch.no_grad():\n",
    "            for p in self.grus.parameters():\n",
    "                p.add_(torch.randn_like(p),alpha=scale)\n",
    "            for p in self.linears.parameters():\n",
    "                p.add_(torch.randn_like(p),alpha=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f871e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units, n_layers=2):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn_units = rnn_units\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                     )\n",
    "        self.pos_encoding = TrainablePositionalEncoding(embedding_dim)\n",
    "        self.grus = nn.ModuleList()\n",
    "        self.linears = nn.ModuleList()\n",
    "        self.initial_states = nn.ParameterList()\n",
    "        for submodel_layers in range(1,n_layers+1):\n",
    "            submodel_gru = nn.GRU(input_size=embedding_dim,\n",
    "                                          hidden_size=self.rnn_units,\n",
    "                                          num_layers=submodel_layers,\n",
    "                                          batch_first=True,\n",
    "                                         )\n",
    "            submodel_linear = nn.Linear(rnn_units,\n",
    "                                                vocab_size,\n",
    "                                                bias=False,\n",
    "                                               )\n",
    "            self.grus.append(submodel_gru)\n",
    "            self.linears.append(submodel_linear)\n",
    "            self.initial_states.append(nn.Parameter(torch.randn((submodel_layers,self.rnn_units,))))\n",
    "        self.bias = nn.Parameter(torch.randn((vocab_size,)))\n",
    "    def batch_initial_states(self,batch_size):\n",
    "        states = [ init_state.repeat((batch_size,1,1)).permute(1,0,2) for init_state in self.initial_states ]\n",
    "        return(states)\n",
    "    def forward(self, inputs, encoding_tensor, lengths, states=None):\n",
    "        if states is None:\n",
    "            states = self.batch_initial_states(len(lengths))\n",
    "        batch_size = len(lengths)\n",
    "        x = self.embedding(inputs[...,0])\n",
    "        x += self.pos_encoding(inputs[...,1].float())\n",
    "        x += encoding_tensor[:,None,:]\n",
    "        x = torch.nn.utils.rnn.pack_padded_sequence(x,lengths,batch_first=True,enforce_sorted=False)\n",
    "        out = 0\n",
    "        for k in range(len(self.grus)):\n",
    "            # Apply GRU\n",
    "            state = states[k]\n",
    "            submodel_gru = self.grus[k]\n",
    "            sub_out, state = submodel_gru(x,state)\n",
    "            states[k] = state\n",
    "            \n",
    "            # Apply linear transform\n",
    "            sub_out,_ = torch.nn.utils.rnn.pad_packed_sequence(sub_out, batch_first=True)\n",
    "            submodel_linear = self.linears[k]\n",
    "            sub_out = submodel_linear(sub_out)\n",
    "            \n",
    "            # Collect in output\n",
    "            out += sub_out\n",
    "        \n",
    "        out += self.bias[None,None,:]\n",
    "        return(out,states)\n",
    "    def noisify(self,scale):\n",
    "        with torch.no_grad():\n",
    "            for p in self.grus.parameters():\n",
    "                p.add_(torch.randn_like(p),alpha=scale)\n",
    "            for p in self.linears.parameters():\n",
    "                p.add_(torch.randn_like(p),alpha=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75a34c5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(90, 256)\n",
      "  (pos_encoding): TrainablePositionalEncoding(\n",
      "    (exp_linear): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (angle_linear): Linear(in_features=1, out_features=128, bias=False)\n",
      "  )\n",
      "  (grus): ModuleList(\n",
      "    (0): GRU(256, 256, batch_first=True)\n",
      "    (1): GRU(256, 256, num_layers=2, batch_first=True)\n",
      "    (2): GRU(256, 256, num_layers=3, batch_first=True)\n",
      "    (3): GRU(256, 256, num_layers=4, batch_first=True)\n",
      "    (4): GRU(256, 256, num_layers=5, batch_first=True)\n",
      "  )\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (initial_states): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 1x256 (GPU 0)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 2x256 (GPU 0)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 3x256 (GPU 0)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 4x256 (GPU 0)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 5x256 (GPU 0)]\n",
      "  )\n",
      ")\n",
      "Decoder(\n",
      "  (embedding): Embedding(90, 256)\n",
      "  (pos_encoding): TrainablePositionalEncoding(\n",
      "    (exp_linear): Linear(in_features=1, out_features=128, bias=True)\n",
      "    (angle_linear): Linear(in_features=1, out_features=128, bias=False)\n",
      "  )\n",
      "  (grus): ModuleList(\n",
      "    (0): GRU(256, 256, batch_first=True)\n",
      "    (1): GRU(256, 256, num_layers=2, batch_first=True)\n",
      "    (2): GRU(256, 256, num_layers=3, batch_first=True)\n",
      "    (3): GRU(256, 256, num_layers=4, batch_first=True)\n",
      "    (4): GRU(256, 256, num_layers=5, batch_first=True)\n",
      "  )\n",
      "  (linears): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=90, bias=False)\n",
      "    (1): Linear(in_features=256, out_features=90, bias=False)\n",
      "    (2): Linear(in_features=256, out_features=90, bias=False)\n",
      "    (3): Linear(in_features=256, out_features=90, bias=False)\n",
      "    (4): Linear(in_features=256, out_features=90, bias=False)\n",
      "  )\n",
      "  (initial_states): ParameterList(\n",
      "      (0): Parameter containing: [torch.cuda.FloatTensor of size 1x256 (GPU 0)]\n",
      "      (1): Parameter containing: [torch.cuda.FloatTensor of size 2x256 (GPU 0)]\n",
      "      (2): Parameter containing: [torch.cuda.FloatTensor of size 3x256 (GPU 0)]\n",
      "      (3): Parameter containing: [torch.cuda.FloatTensor of size 4x256 (GPU 0)]\n",
      "      (4): Parameter containing: [torch.cuda.FloatTensor of size 5x256 (GPU 0)]\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(dataset.vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 256\n",
    "n_layers = 5\n",
    "\n",
    "encoder = Encoder(vocab_size=vocab_size,\n",
    "                  out_dim = embedding_dim,\n",
    "                  embedding_dim = embedding_dim,\n",
    "                  rnn_units=rnn_units,\n",
    "                  n_layers = n_layers,\n",
    "             )\n",
    "encoder.to(device)\n",
    "print(encoder)\n",
    "\n",
    "decoder = Decoder(vocab_size=vocab_size,\n",
    "                  embedding_dim = embedding_dim,\n",
    "                  rnn_units=rnn_units,\n",
    "                  n_layers = n_layers,\n",
    "             )\n",
    "decoder.to(device)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79403269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder parameters: 6277760\n",
      "decoder parameters: 6063834\n"
     ]
    }
   ],
   "source": [
    "print('encoder parameters:',sum( np.prod(p.shape) for p in encoder.parameters()))\n",
    "print('decoder parameters:',sum( np.prod(p.shape) for p in decoder.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f4707f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoder\n",
      "Loaded decoder\n"
     ]
    }
   ],
   "source": [
    "if load_model:\n",
    "    try:\n",
    "        encoder.load_state_dict(torch.load(encoder_name))\n",
    "        encoder.to(device)\n",
    "        print('Loaded encoder')\n",
    "    except:\n",
    "        print('Not loading encoder')\n",
    "    try:\n",
    "        decoder.load_state_dict(torch.load(decoder_name))\n",
    "        decoder.to(device)\n",
    "        print('Loaded decoder')\n",
    "    except:\n",
    "        print('Not loading decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e3024d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "tensor([[[1, 0],\n",
      "         [0, 0]]], device='cuda:0')\n",
      "\r\n",
      "\n",
      "\n",
      "torch.Size([1, 77, 2])\n",
      "tensor([[[ 1,  0],\n",
      "         [53,  0],\n",
      "         [64,  0],\n",
      "         [74,  0],\n",
      "         [68,  0],\n",
      "         [ 2,  1],\n",
      "         [66,  1],\n",
      "         [64,  1],\n",
      "         [81,  1],\n",
      "         [68,  1],\n",
      "         [ 2,  2],\n",
      "         [78,  2],\n",
      "         [69,  2],\n",
      "         [ 2,  3],\n",
      "         [88,  3],\n",
      "         [78,  3],\n",
      "         [84,  3],\n",
      "         [81,  3],\n",
      "         [82,  3],\n",
      "         [68,  3],\n",
      "         [75,  3],\n",
      "         [69,  3],\n",
      "         [15,  0],\n",
      "         [ 2,  1],\n",
      "         [53,  1],\n",
      "         [71,  1],\n",
      "         [68,  1],\n",
      "         [ 2,  2],\n",
      "         [79,  2],\n",
      "         [81,  2],\n",
      "         [72,  2],\n",
      "         [66,  2],\n",
      "         [68,  2],\n",
      "         [ 2,  3],\n",
      "         [78,  3],\n",
      "         [69,  3],\n",
      "         [ 2,  4],\n",
      "         [74,  4],\n",
      "         [78,  4],\n",
      "         [75,  4],\n",
      "         [83,  4],\n",
      "         [78,  4],\n",
      "         [ 2,  5],\n",
      "         [83,  5],\n",
      "         [64,  5],\n",
      "         [77,  5],\n",
      "         [74,  5],\n",
      "         [82,  5],\n",
      "         [ 2,  6],\n",
      "         [71,  6],\n",
      "         [64,  6],\n",
      "         [82,  6],\n",
      "         [ 2,  7],\n",
      "         [73,  7],\n",
      "         [84,  7],\n",
      "         [76,  7],\n",
      "         [79,  7],\n",
      "         [68,  7],\n",
      "         [67,  7],\n",
      "         [ 2,  8],\n",
      "         [83,  8],\n",
      "         [71,  8],\n",
      "         [81,  8],\n",
      "         [78,  8],\n",
      "         [84,  8],\n",
      "         [70,  8],\n",
      "         [71,  8],\n",
      "         [ 2,  9],\n",
      "         [83,  9],\n",
      "         [71,  9],\n",
      "         [68,  9],\n",
      "         [ 2, 10],\n",
      "         [81, 10],\n",
      "         [78, 10],\n",
      "         [78, 10],\n",
      "         [69, 10],\n",
      "         [15,  0]]], device='cuda:0')\n",
      "\r",
      "Take care of yourself. The price of kolto tanks has jumped through the roof.\n",
      "00011111222333333333011112222223334444445555556666777777788888888999910101010100\n",
      "torch.Size([1, 256])\n",
      "tensor([[ 5.4615e-01, -3.6508e-01,  7.3397e-02, -1.1297e+00, -3.2137e-01,\n",
      "          3.4318e-01,  4.0535e-02, -9.4419e-02,  4.3588e-01, -3.6524e-01,\n",
      "         -2.5165e-01, -3.9792e-02, -1.5962e-02,  5.2174e-01, -6.1861e-01,\n",
      "         -2.9377e-01,  2.7895e-01, -2.1404e-01, -4.1927e-02,  5.4340e-01,\n",
      "          1.0427e-01, -6.6605e-01,  8.7426e-02,  4.6228e-01, -5.4917e-02,\n",
      "          1.1997e+00, -6.3003e-01, -4.4910e-01,  3.9389e-01,  1.0787e-01,\n",
      "          6.5549e-01,  2.3855e-01, -2.5718e-03, -5.6108e-01,  2.1846e-01,\n",
      "         -1.8350e-01,  4.1993e-02, -1.0618e+00,  5.0263e-01,  2.3223e-01,\n",
      "          1.0589e+00,  1.2613e-01,  1.0097e-01,  6.6272e-01, -2.0719e-01,\n",
      "          6.8795e-01,  6.5932e-01,  4.3834e-02, -2.6617e-01, -4.5496e-01,\n",
      "         -7.0352e-01, -2.8340e-01, -5.2527e-01, -1.7873e-01,  6.0085e-01,\n",
      "         -9.5145e-01,  2.1731e-01, -2.9172e-01,  2.5888e-01, -4.4066e-01,\n",
      "         -2.5745e-01,  7.7430e-01, -5.9703e-01, -1.1070e-01,  6.9024e-01,\n",
      "          4.8485e-02, -2.9175e-01, -1.0029e-01,  6.4086e-01,  2.6151e-01,\n",
      "         -2.9136e-01,  1.4680e-01,  6.1170e-01, -5.4060e-01,  6.6186e-01,\n",
      "          6.6426e-01, -1.7152e-01, -1.0402e+00,  1.1481e-01,  4.3583e-02,\n",
      "         -8.7093e-01, -2.2776e-01, -2.5944e-03, -1.5653e-01,  4.6270e-02,\n",
      "          1.7784e-01, -2.3434e-01,  7.9216e-01, -9.3935e-01, -8.3468e-02,\n",
      "         -5.4291e-01, -7.4788e-01, -1.2751e-04,  2.4347e-01, -4.2709e-02,\n",
      "         -3.3027e-01,  2.0994e-01,  1.3269e+00, -3.2185e-01, -6.7454e-01,\n",
      "          1.1040e-01,  3.5260e-01,  2.7470e-01,  3.6515e-01,  3.5326e-01,\n",
      "         -3.1280e-01,  4.1201e-01, -3.0483e-01,  1.0232e+00,  4.9697e-01,\n",
      "          1.6276e-01,  5.1996e-01, -3.3876e-01,  5.9521e-01, -1.0385e-01,\n",
      "         -4.8798e-01,  2.3512e-01, -7.8908e-02, -2.1361e-01,  5.1776e-01,\n",
      "          5.4729e-01,  1.7903e-01,  2.8971e-01,  4.8197e-03,  7.7447e-01,\n",
      "          2.7681e-02,  6.0227e-01,  2.0512e-01, -1.5490e-01, -5.9778e-01,\n",
      "         -6.3689e-01, -3.0174e-01,  2.0253e-01,  1.0615e-02,  5.1577e-01,\n",
      "          8.9649e-01, -1.3622e-01,  1.1396e-01, -6.6884e-02,  6.9922e-01,\n",
      "         -2.9571e-01,  1.1411e-01, -2.3797e-01, -3.5574e-01,  5.0410e-01,\n",
      "         -2.0405e-01,  3.6208e-01, -1.1647e-01, -2.9492e-01,  2.0140e-01,\n",
      "         -5.1809e-01, -2.4839e-01, -4.8468e-01,  4.2196e-01, -5.8335e-01,\n",
      "         -9.7418e-01, -5.5142e-01, -1.1762e+00, -3.0875e-01, -2.7641e-01,\n",
      "         -4.5975e-01, -2.8561e-01, -2.1127e-01, -7.5254e-02, -2.5329e-01,\n",
      "         -9.1037e-01,  3.0967e-01,  6.7249e-01, -4.0738e-01, -3.8805e-01,\n",
      "          2.7243e-01, -4.1068e-02, -4.7514e-01, -8.0186e-02,  3.7517e-01,\n",
      "          4.5948e-02, -2.7222e-01,  4.4197e-01, -3.1844e-01,  6.1492e-01,\n",
      "          6.6630e-01, -6.1603e-01,  2.1665e-01, -1.8770e-01, -1.7525e-01,\n",
      "         -2.4644e-02, -6.9918e-01,  3.7824e-01, -3.1947e-02, -4.9652e-02,\n",
      "         -1.2430e-01,  4.2977e-01,  3.4637e-01, -2.3225e-01, -6.6897e-01,\n",
      "         -4.0014e-01, -4.7506e-01,  3.1181e-01, -1.5224e-01,  1.7119e-01,\n",
      "          2.8895e-01, -2.1074e-01, -2.3187e-01, -3.7406e-01,  4.8109e-01,\n",
      "          1.1782e+00, -3.9467e-01,  5.0156e-01, -2.0179e-01,  6.4909e-01,\n",
      "          5.1098e-02,  3.4738e-01,  3.7656e-01, -1.6936e-01, -9.0846e-01,\n",
      "          1.9774e-01, -1.2492e-01,  4.8415e-01, -1.6978e+00,  4.9570e-01,\n",
      "          5.8486e-02, -3.7593e-02, -3.3901e-01, -2.9974e-01, -1.4439e-01,\n",
      "          4.1857e-02,  1.3054e-01, -6.3839e-02, -2.4983e-01, -4.1221e-01,\n",
      "         -1.8388e-01,  2.3074e-01, -3.5291e-01, -9.9336e-02,  7.4785e-01,\n",
      "         -7.7691e-01, -1.4096e-01,  3.8269e-01,  9.5854e-02, -5.2175e-01,\n",
      "         -1.9554e-01,  7.5807e-01, -3.7221e-02,  3.2499e-02, -4.5381e-01,\n",
      "         -4.0642e-01,  3.2208e-01,  1.0102e-01,  2.1824e-01,  4.1254e-01,\n",
      "         -4.7061e-03,  2.2779e-01, -4.5977e-01, -1.3308e-01,  1.7264e-01,\n",
      "          6.1454e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[tensor([[[ 1.5318e-01, -1.9330e-01,  3.3411e-01,  5.7565e-01, -8.9564e-01,\n",
      "           3.0211e-01, -9.6995e-01, -5.2348e-01,  9.7116e-01, -2.9565e-01,\n",
      "           7.1515e-01,  8.8886e-01, -8.1984e-01,  1.5839e-01, -9.3866e-01,\n",
      "          -8.5966e-01,  9.5788e-01,  7.3754e-01,  5.0925e-01,  7.4533e-01,\n",
      "          -9.5424e-01, -7.7429e-01,  5.4827e-01,  8.2272e-01, -3.5968e-01,\n",
      "          -9.8741e-01, -9.2970e-01,  7.4487e-01,  8.6208e-01, -4.8445e-01,\n",
      "           9.5985e-01,  5.6427e-01,  6.2489e-01,  9.6479e-01,  9.9166e-01,\n",
      "          -7.5551e-01, -7.1326e-01, -8.7470e-01,  9.0951e-01, -2.3563e-01,\n",
      "           9.9075e-01,  7.8329e-03,  7.6265e-01,  8.2107e-01, -9.5246e-01,\n",
      "           4.3768e-02,  4.1908e-01, -4.4679e-01,  9.4322e-01,  7.6656e-01,\n",
      "          -9.4663e-01,  2.6975e-01,  7.5394e-01,  8.7019e-01, -7.4268e-02,\n",
      "          -2.6100e-02, -9.7888e-01, -7.5550e-01, -6.6520e-01, -4.7176e-02,\n",
      "          -9.5376e-01, -7.3014e-01,  9.6544e-01, -7.4944e-01, -7.7246e-01,\n",
      "           4.9833e-01, -9.8573e-01,  9.2279e-01,  8.8947e-01,  8.0237e-01,\n",
      "          -9.6826e-01,  6.8203e-01,  7.8326e-01, -4.5149e-01, -8.8995e-01,\n",
      "          -9.1843e-01, -8.1306e-01, -9.7652e-01, -7.1585e-01,  4.4313e-01,\n",
      "           1.5350e-01,  5.5782e-01,  9.4266e-01,  3.4303e-01, -9.6172e-01,\n",
      "          -9.1530e-01,  7.4903e-01, -9.1682e-01,  1.2327e-02, -1.6059e-01,\n",
      "           8.9281e-01,  8.5472e-01,  5.0934e-01,  9.4960e-01,  1.2470e-02,\n",
      "          -9.4094e-01, -9.4300e-01,  6.3320e-01,  7.6663e-01, -2.3368e-01,\n",
      "           4.4490e-01,  5.2886e-01,  8.7727e-01, -8.6106e-02, -6.9631e-01,\n",
      "           8.8271e-01, -9.1901e-01,  9.7607e-01, -6.4544e-01, -9.5905e-01,\n",
      "           5.0911e-01,  8.3279e-01,  2.0391e-01,  9.7575e-01, -9.7449e-01,\n",
      "          -9.8296e-01, -4.4516e-01,  7.7961e-01,  6.4015e-01, -4.3031e-01,\n",
      "          -9.3236e-01, -5.2162e-01,  8.6815e-01, -5.6341e-01,  9.9155e-01,\n",
      "           1.4589e-01,  8.5483e-01, -7.2317e-01,  8.6942e-02, -6.4622e-01,\n",
      "           5.3952e-01,  2.6748e-01, -9.4343e-01,  6.3312e-01, -7.3346e-01,\n",
      "          -6.0953e-01, -7.9609e-01, -8.9030e-01,  9.8154e-01, -9.0512e-01,\n",
      "           2.7887e-01, -5.9725e-01,  9.8782e-01, -5.0860e-01,  6.5629e-01,\n",
      "           9.2600e-01, -7.2612e-01,  9.2011e-01,  2.8915e-01,  2.3898e-01,\n",
      "          -5.8086e-01,  8.2925e-01, -7.7273e-01, -6.2580e-01,  7.6509e-02,\n",
      "           1.9431e-01,  3.9275e-01,  8.7470e-01,  5.6048e-01,  8.1581e-01,\n",
      "          -9.1475e-01, -9.2334e-01, -8.7498e-01,  7.3821e-01,  4.4773e-01,\n",
      "           9.7257e-01, -4.6174e-01,  4.2432e-01, -7.4739e-01,  8.3174e-01,\n",
      "           9.9308e-01, -2.1207e-01,  8.6588e-01,  9.1741e-01,  8.8170e-01,\n",
      "          -8.7783e-01,  9.9896e-01,  9.7026e-01, -9.6390e-01,  5.8397e-01,\n",
      "           6.4601e-01,  8.5212e-01,  8.8388e-01,  9.4405e-01,  9.8373e-01,\n",
      "          -8.5372e-02, -8.9195e-01, -7.1194e-01,  8.1258e-01, -9.1357e-02,\n",
      "          -9.1297e-01,  9.5440e-01,  7.1198e-01, -2.4005e-01, -6.6882e-01,\n",
      "          -5.1911e-01,  9.6481e-01, -2.8593e-01, -9.7326e-01,  8.5342e-01,\n",
      "          -9.8657e-01,  7.0770e-01,  8.8404e-01, -3.2678e-01, -1.9087e-01,\n",
      "           4.8351e-01, -9.5989e-01, -6.8821e-01, -6.6637e-01, -3.2753e-02,\n",
      "          -4.4716e-01, -9.0008e-01, -9.8136e-01, -3.9295e-02, -4.4722e-01,\n",
      "          -3.5954e-02,  3.5709e-01,  6.3082e-01, -8.7152e-01, -4.2626e-01,\n",
      "           6.2369e-01, -9.6863e-01,  2.2714e-01, -8.9539e-01, -9.4457e-01,\n",
      "          -9.4680e-01, -1.6257e-01,  9.2596e-01, -4.5190e-01,  2.4595e-01,\n",
      "          -8.2960e-01, -6.6604e-01, -9.7668e-01, -6.0235e-01,  6.7436e-01,\n",
      "           6.9231e-01, -6.5446e-02,  9.3188e-01,  3.5124e-02,  6.6100e-01,\n",
      "          -8.7803e-01,  7.2821e-01,  8.5688e-01, -8.0332e-02, -8.5817e-01,\n",
      "           3.0579e-01, -9.9208e-01,  9.8078e-01,  9.8111e-01, -6.6593e-01,\n",
      "          -5.0805e-01, -4.3710e-01, -9.6041e-05, -7.8352e-01, -8.3166e-01,\n",
      "          -9.3041e-01]]], device='cuda:0', grad_fn=<IndexSelectBackward0>), tensor([[[ 0.5612, -0.9969,  0.7710,  0.8345, -0.7064,  0.9741, -0.3016,\n",
      "           0.5050, -0.3001,  0.4871, -0.8411, -0.6510,  0.9015, -0.9875,\n",
      "          -0.9368, -0.9614, -0.4181,  0.9244,  0.9704, -0.9968, -0.4760,\n",
      "          -0.3780,  0.5425, -0.4522,  0.9293, -0.9896, -0.9943, -0.7207,\n",
      "           0.8571,  0.7973,  0.8130,  0.8470, -0.4916, -0.7455,  0.9075,\n",
      "          -0.3848, -0.7668,  0.9107, -0.9157, -0.2908, -0.9428, -0.8053,\n",
      "           0.8084, -0.9967,  0.7701, -0.7559, -0.1382,  0.9687,  0.7193,\n",
      "           0.8867,  0.9674,  0.9872, -0.3371,  0.6747, -0.1828, -0.9241,\n",
      "          -0.9836, -0.3893,  0.8291,  0.9305, -0.9823,  0.3232, -0.9690,\n",
      "           0.7864,  0.9982,  0.9666,  0.5206,  0.9146, -0.3337,  0.9290,\n",
      "           0.1317,  0.8352,  0.9256,  0.8550, -0.9088,  0.0212,  0.9796,\n",
      "           0.6673, -0.5190,  0.9406, -0.1196, -0.3105, -0.7621, -0.2417,\n",
      "           0.2416, -0.8447,  0.6872, -0.8498,  0.2426,  0.5669,  0.1315,\n",
      "          -0.9656,  0.9761,  0.6371, -0.3076, -0.2057, -0.9896,  0.9827,\n",
      "          -0.8993, -0.3514, -0.9993,  0.8239,  0.8749,  0.9843,  0.8366,\n",
      "          -0.6989,  0.8536, -0.2099,  0.7418,  0.0278,  0.9955, -0.1767,\n",
      "          -0.8237,  0.7212,  0.8196, -0.3524,  0.8094,  0.5227, -0.4563,\n",
      "           0.6984,  0.9930,  0.2812, -0.7059, -0.9898, -0.9413,  0.3724,\n",
      "           0.3655,  0.9173, -0.6875, -0.2001,  0.3365, -0.3544,  0.9177,\n",
      "           0.9965,  0.9477,  0.6998, -0.9348, -0.9581,  0.9984, -0.9268,\n",
      "          -0.8925, -0.9022, -0.8619,  0.4615, -0.0062,  0.9533,  0.2307,\n",
      "          -0.0837, -0.5405,  0.8786, -0.1678,  0.3701, -0.9885,  0.9973,\n",
      "           0.9701,  0.8785, -0.3318,  0.8661, -0.1215, -0.9535,  0.9639,\n",
      "          -0.9330, -0.5537,  0.9669,  0.4019,  0.8774,  0.5835,  0.9848,\n",
      "          -0.8622,  0.9634, -0.1899, -0.9566,  0.9226,  0.8024,  0.6413,\n",
      "           0.5647,  0.9466, -0.9781, -0.9413,  0.7049,  0.0439, -0.6897,\n",
      "           0.9605, -0.6771, -0.3127,  0.2760,  0.8107, -0.9999,  0.6395,\n",
      "           0.2856, -0.1273, -0.9725,  0.9993,  0.9835,  0.9591, -0.8856,\n",
      "          -0.5811, -0.8709,  0.8406,  0.5612, -0.8229, -0.9381,  0.3267,\n",
      "          -0.9841, -0.9975, -0.9614,  0.9471,  0.3931,  0.9166, -0.9879,\n",
      "           0.9646,  0.9593,  0.7982, -0.8550, -0.5660,  0.9524, -0.9225,\n",
      "           0.7227, -0.9727,  0.0144, -0.5380,  0.8824,  0.5069,  0.5373,\n",
      "          -0.6014,  0.6311, -0.5270,  0.8107,  0.9479, -0.8168,  0.1939,\n",
      "          -0.3420,  0.9314,  0.5351,  0.6067,  0.8910, -0.3787,  0.0146,\n",
      "          -0.3801, -0.0802, -0.6842,  0.9803, -0.9931, -0.9365, -0.5787,\n",
      "           0.9767,  0.8109, -0.6556,  0.9657,  0.8044,  0.9332, -0.6742,\n",
      "          -0.9668,  0.9226, -0.7908, -0.7619]],\n",
      "\n",
      "        [[-0.1817, -0.9643,  0.6175, -0.1398,  0.9188, -0.1085, -0.0694,\n",
      "          -0.8853,  0.4165, -0.7816, -0.5952,  0.9877, -0.9736, -0.8927,\n",
      "          -0.1171, -0.5534, -0.5261, -0.8323,  0.2517, -0.9763,  0.9101,\n",
      "           0.0930,  0.9710,  0.6522,  0.8485,  0.2400,  0.3871,  0.7716,\n",
      "           0.4684, -0.2039,  0.8523,  0.8778, -0.8888, -0.9431, -0.9060,\n",
      "           0.7476, -0.9073, -0.8513, -0.9500, -0.7678,  0.8981,  0.5974,\n",
      "           0.5067, -0.9641, -0.5727, -0.8076,  0.3313, -0.4603, -0.6374,\n",
      "           0.9358, -0.8608, -0.2696,  0.8234, -0.7416,  0.4205,  0.7974,\n",
      "          -0.1644,  0.1346,  0.5029, -0.9623, -0.7643,  0.9823,  0.8311,\n",
      "          -0.7428,  0.9591,  0.3812, -0.9734, -0.8654, -0.9384,  0.3528,\n",
      "          -0.9856, -0.8597, -0.9735,  0.5834, -0.6365, -0.1557,  0.9734,\n",
      "          -0.5021, -0.7100, -0.6356, -0.1297, -0.6436,  0.7655, -0.4327,\n",
      "          -0.7952,  0.7887, -0.2656,  0.9958,  0.9641,  0.8793, -0.2975,\n",
      "          -0.0124,  0.5788, -0.4079, -0.8828,  0.0307,  0.9281, -0.7719,\n",
      "           0.9905,  0.9751,  0.6782,  0.6398,  0.4466,  0.4868, -0.8566,\n",
      "           0.8051,  0.9526, -0.1939,  0.7412,  0.9406, -0.8789, -0.6455,\n",
      "           0.7088,  0.6979, -0.9009, -0.9286, -0.8078, -0.4728,  0.6425,\n",
      "           0.7368, -0.7962,  0.8083,  0.3014, -0.8480,  0.6167, -0.3569,\n",
      "           0.2238,  0.9340, -0.6981, -0.9018, -0.7100,  0.9937, -0.9338,\n",
      "           0.2299, -0.6032,  0.9800, -0.9747,  0.9254,  0.9334,  0.7409,\n",
      "          -0.9960,  0.7136,  0.4715, -0.9564,  0.3458,  0.8629, -0.9672,\n",
      "          -0.9730,  0.1978,  0.9690,  0.7894, -0.7524,  0.9943,  0.4324,\n",
      "          -0.6057, -0.9573, -0.9433,  0.7322, -0.9421,  0.3463, -0.9972,\n",
      "           0.7880,  0.8142,  0.5716,  0.8226, -0.8619,  0.9351, -0.4072,\n",
      "          -0.8996,  0.9349, -0.3740,  0.9124,  0.1616,  0.4607,  0.1643,\n",
      "          -0.0236, -0.1342, -0.8067,  0.7898, -0.5922,  0.7658,  0.9747,\n",
      "          -0.7598, -0.5032,  0.5363, -0.9352,  0.1598,  0.8138, -0.9529,\n",
      "           0.2036, -0.1868, -0.7413,  0.8775,  0.5276,  0.7646, -0.6791,\n",
      "           0.2296, -0.0042, -0.2237, -0.5352,  0.9514,  0.2782,  0.9694,\n",
      "          -0.3111,  0.4983, -0.9672,  0.6475, -0.9701,  0.8823,  0.9837,\n",
      "           0.7397, -0.6420, -0.5483, -0.6307, -0.8615,  0.8007,  0.1509,\n",
      "          -0.2765, -0.8171, -0.8598,  0.3470, -0.1720, -0.0312, -0.6250,\n",
      "           0.9980, -0.8534,  0.4002,  0.9744,  0.9880, -0.7969,  0.9751,\n",
      "           0.0411, -0.8323,  0.6223,  0.5740,  0.4775,  0.9727, -0.9821,\n",
      "           0.1018, -0.6308, -0.4991,  0.5679, -0.8869,  0.8869, -0.9797,\n",
      "          -0.6463, -0.6401, -0.5586,  0.8932,  0.9721, -0.5520, -0.6748,\n",
      "          -0.7830,  0.1730, -0.8947, -0.7193]]], device='cuda:0',\n",
      "       grad_fn=<IndexSelectBackward0>), tensor([[[-0.7790, -0.8618, -0.6411, -0.4093, -0.9100,  0.4427,  0.8789,\n",
      "          -0.8313, -0.8393, -0.3524, -0.2217, -0.3781, -0.9557, -0.7852,\n",
      "          -0.0477, -0.0048,  0.9062,  0.8298,  0.4607,  0.8972, -0.0514,\n",
      "          -0.9585,  0.9968, -0.9670,  0.6126, -0.9506, -0.3618, -0.5103,\n",
      "           0.8180,  0.4712, -0.0451, -0.5668, -0.6198,  0.0522, -0.2100,\n",
      "           0.8724,  0.2286, -0.4347, -0.4515,  0.0032,  0.9205,  0.9348,\n",
      "          -0.6236,  0.9231,  0.8878, -0.0331,  0.6951,  0.9629,  0.2982,\n",
      "           0.9180, -0.7362,  0.3234,  0.6622,  0.1044, -0.4111, -0.9833,\n",
      "           0.9370,  0.6852, -0.8363,  0.6501, -0.7841, -0.6905, -0.7965,\n",
      "          -0.8723,  0.8987,  0.6199,  0.5051, -0.5464, -0.4455,  0.6102,\n",
      "          -0.2367, -0.9490, -0.7834, -0.8326, -0.3306,  0.9820,  0.3038,\n",
      "           0.8789, -0.7746, -0.9864, -0.8381,  0.9033, -0.1036, -0.8499,\n",
      "           0.9599,  0.9812,  0.8828,  0.5150,  0.8874, -0.6850,  0.7557,\n",
      "           0.7674,  0.9647,  0.3285, -0.9953, -0.4523, -0.6735, -0.3042,\n",
      "          -0.8365, -0.0741,  0.9105, -0.1383,  0.0379,  0.9774,  0.5683,\n",
      "          -0.0445,  0.5990, -0.9678, -0.4303,  0.3656,  0.9177,  0.9877,\n",
      "           0.7931, -0.3043,  0.9013, -0.6157,  0.8351,  0.9735,  0.3559,\n",
      "          -0.9808, -0.6569, -0.7908,  0.5437, -0.4206,  0.6236,  0.8162,\n",
      "           0.6848,  0.9932,  0.9028, -0.0297, -0.4125,  0.7167,  0.9013,\n",
      "          -0.8372,  0.8040, -0.9519, -0.9998,  0.3931,  0.9843, -0.4027,\n",
      "          -0.7549, -0.9932,  0.5465,  0.9140, -0.2996,  0.4098, -0.8241,\n",
      "          -0.9072,  0.7818, -0.8456, -0.8004,  0.9796, -0.3008,  0.0212,\n",
      "          -0.8262, -0.8554,  0.1264, -0.1749, -0.9654, -0.1493,  0.7611,\n",
      "          -0.9830,  0.2532,  0.9575, -0.3330,  0.7189,  0.0943, -0.0341,\n",
      "          -0.9214,  0.3891, -0.9303, -0.6820, -0.9403,  0.9470,  0.9643,\n",
      "           0.9482,  0.9562,  0.3861,  0.9853, -0.9595, -0.6496,  0.9925,\n",
      "          -0.9258, -0.7730, -0.8073,  0.1519, -0.0883, -0.8322, -0.2827,\n",
      "           0.8550, -0.8496, -0.8065, -0.2474, -0.9051, -0.6037,  0.4104,\n",
      "           0.0414, -0.9920,  0.9082, -0.8832,  0.0455,  0.7265,  0.9926,\n",
      "           0.9167,  0.1285, -0.8127, -0.6399, -0.8949, -0.6780, -0.9689,\n",
      "          -0.9373,  0.4309,  0.9711, -0.9182,  0.0590,  0.5438, -0.2708,\n",
      "          -0.2448,  0.8798,  0.8954,  0.8068,  0.7459,  0.9070, -0.8595,\n",
      "           0.1258, -0.9982,  0.1921, -0.1883,  0.9668,  0.4876,  0.8492,\n",
      "          -0.2907,  0.2047, -0.5896,  0.9594, -0.8311, -0.0167,  0.7678,\n",
      "          -0.9946,  0.6318, -0.8371,  0.9236,  0.9545, -0.9965,  0.2325,\n",
      "          -0.7548, -0.4292, -0.4102, -0.9416, -0.7088,  0.9113, -0.6343,\n",
      "          -0.8153,  0.9197, -0.1827,  0.9136]],\n",
      "\n",
      "        [[ 0.3871,  0.6202,  0.0285,  0.5348, -0.7567,  0.5850,  0.1968,\n",
      "          -0.7899,  0.9330, -0.0955, -0.3213, -0.8600,  0.2893, -0.9797,\n",
      "          -0.4653,  0.7098, -0.1070,  0.8689,  0.8095,  0.4104,  0.7054,\n",
      "           0.8760, -0.8820,  0.8731,  0.7595,  0.7441,  0.6170, -0.7292,\n",
      "           0.4033, -0.5025, -0.0839,  0.4289, -0.8689,  0.6585, -0.9980,\n",
      "           0.4699, -0.5990,  0.8862, -0.9566, -0.8004, -0.9402,  0.9598,\n",
      "          -0.9487, -0.5736,  0.9905,  0.7895,  0.7365,  0.6591, -0.4249,\n",
      "          -0.1928, -0.7448, -0.8946, -0.9886,  0.3693,  0.7824, -0.9088,\n",
      "           0.2268,  0.2476, -0.5602, -0.9435,  0.7703,  0.7764,  0.6229,\n",
      "          -0.8080,  0.9931,  0.8415, -0.9573,  0.4066,  0.8483, -0.9737,\n",
      "           0.8084,  0.2139, -0.6811,  0.9127, -0.6272,  0.7518,  0.7048,\n",
      "           0.4496, -0.9015, -0.9796, -0.6831, -0.8103,  0.5025,  0.8009,\n",
      "          -0.6764,  0.0121, -0.6935, -0.8254,  0.8552, -0.4174,  0.1723,\n",
      "           0.3881,  0.1290,  0.4910, -0.8896, -0.9407,  0.7208,  0.9088,\n",
      "          -0.1782, -0.8561,  0.9698, -0.2111,  0.3508, -0.8998,  0.0477,\n",
      "          -0.2482,  0.2109, -0.6485, -0.4330,  0.9658,  0.1944,  0.5360,\n",
      "           0.3965, -0.8904,  0.9872, -0.8450, -0.9425, -0.8747, -0.8351,\n",
      "          -0.9914,  0.0096,  0.9760,  0.0714,  0.8200,  0.9676,  0.2433,\n",
      "           0.6146, -0.9786,  0.5015,  0.9557,  0.9276,  0.9712, -0.8881,\n",
      "           0.4630,  0.5271, -0.9351, -0.9733, -0.7897, -0.7771,  0.9799,\n",
      "          -0.5751, -0.1677,  0.9048,  0.9241, -0.8111,  0.5940, -0.5390,\n",
      "           0.3208,  0.9928,  0.7305, -0.7836,  0.7385,  0.4893, -0.8262,\n",
      "          -0.3861, -0.4269, -0.9677,  0.8007,  0.8020,  0.4211,  0.8510,\n",
      "          -0.8323,  0.7927,  0.9958,  0.5906, -0.3592,  0.7635, -0.8983,\n",
      "           0.4749, -0.3738,  0.2085, -0.1352,  0.5907,  0.1993,  0.8159,\n",
      "          -0.2954,  0.8550,  0.0138,  0.6018,  0.2887,  0.3357,  0.6909,\n",
      "          -0.3417,  0.8815, -0.4091, -0.2740, -0.2820,  0.7543,  0.8664,\n",
      "           0.9534, -0.4280,  0.7260, -0.8982, -0.6548, -0.8916,  0.2465,\n",
      "           0.9851,  0.5419,  0.7178,  0.6066,  0.2303,  0.2609, -0.8720,\n",
      "           0.6653, -0.8698,  0.8184,  0.6307, -0.9835,  0.9942,  0.9958,\n",
      "          -0.2223, -0.5181,  0.1306,  0.8282,  0.5262, -0.8901, -0.8614,\n",
      "          -0.5851, -0.2308,  0.1585,  0.3950,  0.3101, -0.8653, -0.5143,\n",
      "          -0.9727,  0.8050, -0.8785, -0.9365,  0.9025, -0.2859, -0.9122,\n",
      "          -0.4717, -0.4006,  0.3135, -0.8167,  0.9575,  0.1080,  0.8873,\n",
      "          -0.7520,  0.0718, -0.8145, -0.9870,  0.6991, -0.9808, -0.0397,\n",
      "           0.9325,  0.3943, -0.7949,  0.6920,  0.8978, -0.6624,  0.2851,\n",
      "           0.6608,  0.2758, -0.9208,  0.7554]],\n",
      "\n",
      "        [[-0.7192, -0.5305, -0.9427, -0.6597, -0.0823, -0.9002,  0.2247,\n",
      "           0.5300, -0.8645,  0.7195,  0.2231,  0.9103,  0.7491, -0.5277,\n",
      "          -0.4025,  0.9576,  0.2259, -0.9583,  0.9245,  0.9264,  0.2553,\n",
      "          -0.6275, -0.0303,  0.9316,  0.4970,  0.7073, -0.8056, -0.3172,\n",
      "           0.6353,  0.9906,  0.9968, -0.7987, -0.6901,  0.4062,  0.7686,\n",
      "           0.9965,  0.2556, -0.8910, -0.3859, -0.9449,  0.7661,  0.9626,\n",
      "           0.6205, -0.9410,  0.5273,  0.8746, -0.1259, -0.8383, -0.5115,\n",
      "          -0.7451, -0.4149,  0.7526, -0.9079, -0.8754, -0.9910,  0.0320,\n",
      "          -0.9743,  0.8073,  0.9562,  0.1652,  0.5896, -0.9946,  0.3998,\n",
      "          -0.5948,  0.8314, -0.2068, -0.9235, -0.9936, -0.7787, -0.9569,\n",
      "           0.8053,  0.8955,  0.8211,  0.8150,  0.8272,  0.5396, -0.7507,\n",
      "           0.8574,  0.8746,  0.7224,  0.0465,  0.5814,  0.3432,  0.2169,\n",
      "          -0.3219,  0.2690,  0.8062,  0.4657, -0.0510,  0.5280,  0.5436,\n",
      "           0.4327,  0.9542,  0.8722, -0.3271,  0.9671,  0.9671,  0.1615,\n",
      "          -0.9833, -0.7588,  0.9961,  0.8844, -0.9900, -0.3245,  0.9784,\n",
      "           0.3103,  0.8622, -0.8962, -0.8932,  0.4476, -0.6080,  0.6868,\n",
      "          -0.9614,  0.8737, -0.3062,  0.8678, -0.9814, -0.5803, -0.8303,\n",
      "           0.9636, -0.8696,  0.9887, -0.8329,  0.1898, -0.7038,  0.7948,\n",
      "          -0.6091,  0.4631,  0.8580,  0.9004,  0.9099,  0.9936, -0.9961,\n",
      "          -0.5080, -0.3304,  0.9289,  0.6474,  0.6057, -0.9517,  0.4520,\n",
      "          -0.9285, -0.8144, -0.9859,  0.9158, -0.2787, -0.6415,  0.9137,\n",
      "           0.5163, -0.7134,  0.9842,  0.9047,  0.8732, -0.4611, -0.9470,\n",
      "           0.9419, -0.7177,  0.8606,  0.3349, -0.9798,  0.6324,  0.4577,\n",
      "           0.2549, -0.8815,  0.6111,  0.9359, -0.9783, -0.6371,  0.9197,\n",
      "          -0.1977, -0.3733,  0.9521, -0.9357, -0.4659,  0.9225,  0.4835,\n",
      "          -0.2692, -0.9982, -0.1779,  0.9011, -0.8914,  0.9364, -0.1450,\n",
      "           0.9686,  0.9867,  0.9266, -0.7562,  0.8641, -0.7887,  0.0459,\n",
      "           0.7433, -0.5261,  0.9955,  0.8492,  0.6732,  0.2291, -0.9657,\n",
      "          -0.9757, -0.9912,  0.8483, -0.8911,  0.3497,  0.9840,  0.6473,\n",
      "           0.8629,  0.8982, -0.9344, -0.8239,  0.4272, -0.8931, -0.7892,\n",
      "           0.6119,  0.7711,  0.0900,  0.3812,  0.5330, -0.9099, -0.9693,\n",
      "           0.8882,  0.9050, -0.9852, -0.6127,  0.3101,  0.8723, -0.5198,\n",
      "           0.5914, -0.0179,  0.7072, -0.2168, -0.3439,  0.9043, -0.0513,\n",
      "           0.9552,  0.7743,  0.9863, -0.8911,  0.4024,  0.2933, -0.8302,\n",
      "           0.2145,  0.5116, -0.9692, -0.6071,  0.9039,  0.8985, -0.9854,\n",
      "           0.4114, -0.9935, -0.9186, -0.7387, -0.6554,  0.6009,  0.9813,\n",
      "           0.7750, -0.7226, -0.8596,  0.9503]]], device='cuda:0',\n",
      "       grad_fn=<IndexSelectBackward0>), tensor([[[-0.9235,  0.9328,  0.6518,  ..., -0.9882,  0.9609, -0.8590]],\n",
      "\n",
      "        [[-0.5012,  0.3097,  0.5122,  ..., -0.5755,  0.9063, -0.2424]],\n",
      "\n",
      "        [[ 0.9596,  0.4926,  0.5923,  ...,  0.9287, -0.1074, -0.8411]],\n",
      "\n",
      "        [[ 0.4270, -0.2945, -0.6119,  ...,  0.2734, -0.4017, -0.9714]]],\n",
      "       device='cuda:0', grad_fn=<IndexSelectBackward0>), tensor([[[-5.4423e-01,  3.7848e-01,  6.5554e-01,  ...,  9.4077e-01,\n",
      "           7.6826e-01, -6.9035e-01]],\n",
      "\n",
      "        [[-8.0565e-01,  2.1803e-01, -6.2194e-01,  ..., -2.0894e-01,\n",
      "          -1.3191e-01, -4.0235e-01]],\n",
      "\n",
      "        [[ 1.5441e-03, -1.0078e-01, -2.8607e-01,  ..., -4.0646e-02,\n",
      "           5.6399e-01,  5.8721e-01]],\n",
      "\n",
      "        [[-1.1883e-02,  3.0943e-01,  2.3747e-01,  ...,  3.8714e-04,\n",
      "          -3.1462e-01, -1.5108e-01]],\n",
      "\n",
      "        [[-5.3786e-02, -8.3409e-02,  4.9385e-01,  ...,  4.7137e-01,\n",
      "          -2.0919e-02,  2.7146e-01]]], device='cuda:0',\n",
      "       grad_fn=<IndexSelectBackward0>)]\n",
      "Dhre ilte of tour elf, Yheycloce of molfo ponks aov nuspid theeugh oheiwaok \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prevs,ins,outs = dataset[0]\n",
    "N_prevs = len(prevs)\n",
    "N_currents = len(ins)\n",
    "prevs = prevs.to(device)[None,:]\n",
    "ins = ins.to(device)[None,:]\n",
    "outs = outs.to(device)[None,:]\n",
    "prevs = add_positional_info(prevs)\n",
    "ins = add_positional_info(ins)\n",
    "print(prevs.shape)\n",
    "print(prevs)\n",
    "print(dataset.vec2str(prevs[0,:,0]))\n",
    "print(''.join( str(i) for i in prevs[0,:,1].tolist()[2:]))\n",
    "print(ins.shape)\n",
    "print(ins)\n",
    "print(dataset.vec2str(ins[0,:,0]))\n",
    "print(''.join( str(i) for i in ins[0,:,1].tolist()[2:]))\n",
    "encoder_tensor = encoder(prevs,[N_prevs])\n",
    "print(encoder_tensor.shape)\n",
    "print(encoder_tensor)\n",
    "pred, states = decoder(ins,encoder_tensor,[N_currents])\n",
    "print(states)\n",
    "print(dataset.vec2str(torch.exp(pred).squeeze(0).multinomial(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29d9701b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 145, 2])\n",
      "tensor([[[ 1,  0],\n",
      "         [60,  0],\n",
      "         [39,  0],\n",
      "         [68,  0],\n",
      "         [68,  0],\n",
      "         [67,  0],\n",
      "         [ 2,  1],\n",
      "         [83,  1],\n",
      "         [71,  1],\n",
      "         [68,  1],\n",
      "         [ 2,  2],\n",
      "         [65,  2],\n",
      "         [68,  2],\n",
      "         [64,  2],\n",
      "         [82,  2],\n",
      "         [83,  2],\n",
      "         [ 2,  3],\n",
      "         [64,  3],\n",
      "         [77,  3],\n",
      "         [67,  3],\n",
      "         [ 2,  4],\n",
      "         [72,  4],\n",
      "         [83,  4],\n",
      "         [ 2,  5],\n",
      "         [86,  5],\n",
      "         [72,  5],\n",
      "         [75,  5],\n",
      "         [75,  5],\n",
      "         [ 2,  6],\n",
      "         [71,  6],\n",
      "         [68,  6],\n",
      "         [68,  6],\n",
      "         [67,  6],\n",
      "         [ 2,  7],\n",
      "         [88,  7],\n",
      "         [78,  7],\n",
      "         [84,  7],\n",
      "         [81,  7],\n",
      "         [ 2,  8],\n",
      "         [66,  8],\n",
      "         [64,  8],\n",
      "         [75,  8],\n",
      "         [75,  8],\n",
      "         [15,  0],\n",
      "         [ 2,  1],\n",
      "         [53,  1],\n",
      "         [64,  1],\n",
      "         [74,  1],\n",
      "         [68,  1],\n",
      "         [ 2,  2],\n",
      "         [85,  2],\n",
      "         [72,  2],\n",
      "         [79,  2],\n",
      "         [68,  2],\n",
      "         [81,  2],\n",
      "         [82,  2],\n",
      "         [ 2,  3],\n",
      "         [69,  3],\n",
      "         [81,  3],\n",
      "         [78,  3],\n",
      "         [76,  3],\n",
      "         [ 2,  4],\n",
      "         [83,  4],\n",
      "         [71,  4],\n",
      "         [68,  4],\n",
      "         [72,  4],\n",
      "         [81,  4],\n",
      "         [ 2,  5],\n",
      "         [75,  5],\n",
      "         [64,  5],\n",
      "         [72,  5],\n",
      "         [81,  5],\n",
      "         [ 2,  6],\n",
      "         [64,  6],\n",
      "         [77,  6],\n",
      "         [67,  6],\n",
      "         [ 2,  7],\n",
      "         [71,  7],\n",
      "         [64,  7],\n",
      "         [77,  7],\n",
      "         [70,  7],\n",
      "         [ 2,  8],\n",
      "         [83,  8],\n",
      "         [71,  8],\n",
      "         [68,  8],\n",
      "         [76,  8],\n",
      "         [ 2,  9],\n",
      "         [69,  9],\n",
      "         [81,  9],\n",
      "         [78,  9],\n",
      "         [76,  9],\n",
      "         [ 2, 10],\n",
      "         [64, 10],\n",
      "         [65, 10],\n",
      "         [78, 10],\n",
      "         [85, 10],\n",
      "         [68, 10],\n",
      "         [15,  0],\n",
      "         [ 2,  1],\n",
      "         [45,  1],\n",
      "         [68,  1],\n",
      "         [83,  1],\n",
      "         [ 2,  2],\n",
      "         [65,  2],\n",
      "         [75,  2],\n",
      "         [78,  2],\n",
      "         [78,  2],\n",
      "         [67,  2],\n",
      "         [ 2,  3],\n",
      "         [82,  3],\n",
      "         [66,  3],\n",
      "         [68,  3],\n",
      "         [77,  3],\n",
      "         [83,  3],\n",
      "         [ 2,  4],\n",
      "         [83,  4],\n",
      "         [71,  4],\n",
      "         [68,  4],\n",
      "         [ 2,  5],\n",
      "         [70,  5],\n",
      "         [81,  5],\n",
      "         [78,  5],\n",
      "         [84,  5],\n",
      "         [77,  5],\n",
      "         [67,  5],\n",
      "         [ 2,  6],\n",
      "         [78,  6],\n",
      "         [69,  6],\n",
      "         [ 2,  7],\n",
      "         [78,  7],\n",
      "         [84,  7],\n",
      "         [81,  7],\n",
      "         [ 2,  8],\n",
      "         [64,  8],\n",
      "         [77,  8],\n",
      "         [66,  8],\n",
      "         [68,  8],\n",
      "         [82,  8],\n",
      "         [83,  8],\n",
      "         [78,  8],\n",
      "         [81,  8],\n",
      "         [82,  8],\n",
      "         [15,  0],\n",
      "         [61,  0],\n",
      "         [ 0,  0]]], device='cuda:0')\n",
      "\r",
      "[Feed the beast and it will heed your call. Take vipers from their lair and hang them from above. Let blood scent the ground of our ancestors.]\n",
      "\n",
      "00001111222222333344455555666667777788888011111222222233333444444555556666777778888899999101010101010011112222223333334444555555566677778888888888000\n",
      "torch.Size([1, 62, 2])\n",
      "tensor([[[ 1,  0],\n",
      "         [60,  0],\n",
      "         [48,  0],\n",
      "         [65,  0],\n",
      "         [85,  0],\n",
      "         [72,  0],\n",
      "         [78,  0],\n",
      "         [84,  0],\n",
      "         [82,  0],\n",
      "         [75,  0],\n",
      "         [88,  0],\n",
      "         [ 2,  1],\n",
      "         [83,  1],\n",
      "         [71,  1],\n",
      "         [72,  1],\n",
      "         [82,  1],\n",
      "         [ 2,  2],\n",
      "         [86,  2],\n",
      "         [64,  2],\n",
      "         [82,  2],\n",
      "         [ 2,  3],\n",
      "         [78,  3],\n",
      "         [77,  3],\n",
      "         [66,  3],\n",
      "         [68,  3],\n",
      "         [ 2,  4],\n",
      "         [64,  4],\n",
      "         [ 2,  5],\n",
      "         [79,  5],\n",
      "         [75,  5],\n",
      "         [64,  5],\n",
      "         [66,  5],\n",
      "         [68,  5],\n",
      "         [ 2,  6],\n",
      "         [78,  6],\n",
      "         [69,  6],\n",
      "         [ 2,  7],\n",
      "         [70,  7],\n",
      "         [81,  7],\n",
      "         [68,  7],\n",
      "         [64,  7],\n",
      "         [83,  7],\n",
      "         [ 2,  8],\n",
      "         [81,  8],\n",
      "         [72,  8],\n",
      "         [83,  8],\n",
      "         [84,  8],\n",
      "         [64,  8],\n",
      "         [75,  8],\n",
      "         [ 2,  9],\n",
      "         [72,  9],\n",
      "         [76,  9],\n",
      "         [79,  9],\n",
      "         [78,  9],\n",
      "         [81,  9],\n",
      "         [83,  9],\n",
      "         [64,  9],\n",
      "         [77,  9],\n",
      "         [66,  9],\n",
      "         [68,  9],\n",
      "         [15,  0],\n",
      "         [61,  0]]], device='cuda:0')\n",
      "\r",
      "[Obviously this was once a place of great ritual importance.]\n",
      "000000000111112222333334455555566677777788888889999999999900\n",
      "torch.Size([1, 256])\n",
      "tensor([[ 7.4020e-01,  1.2207e-01,  4.4022e-01, -8.3853e-01,  8.0406e-02,\n",
      "          4.2191e-01,  2.3754e-01,  1.7219e-01, -2.0366e-02, -7.8403e-02,\n",
      "          3.3609e-01, -1.6132e+00,  4.0020e-01,  1.3690e+00, -5.3916e-01,\n",
      "          7.0713e-02,  2.8811e-01,  5.3431e-01,  5.3031e-01,  2.9734e-01,\n",
      "          9.0567e-01, -1.1679e+00,  2.9479e-01,  1.8425e-01, -3.5169e-01,\n",
      "          3.8304e-01, -4.3391e-01,  4.1583e-01,  5.5197e-01, -1.0852e-01,\n",
      "          1.9564e-01, -1.1336e+00,  9.3197e-01, -1.3676e+00, -8.4562e-02,\n",
      "         -1.0570e-02,  3.0499e-01, -9.2812e-01, -2.3066e-02,  4.7497e-01,\n",
      "          2.3937e-01,  7.6904e-01,  4.5816e-02,  2.1180e-02, -6.3369e-01,\n",
      "          4.8788e-01, -2.4952e-01, -1.1992e-01, -4.7118e-01, -9.9292e-01,\n",
      "         -5.7735e-01, -3.4938e-01, -5.3253e-01,  1.1581e-01, -9.0062e-02,\n",
      "          1.0039e-01,  2.4226e-02,  4.5437e-01, -7.7791e-02,  6.2578e-01,\n",
      "         -4.7199e-01,  1.5672e-01, -1.2183e+00,  8.4717e-01,  8.1301e-01,\n",
      "         -3.5590e-01,  2.7087e-02, -4.7111e-01,  4.3647e-01, -5.8135e-01,\n",
      "         -1.9907e-01, -7.3153e-02,  1.1405e-01, -3.0162e-01,  5.1029e-02,\n",
      "          3.0034e-01, -4.1447e-02, -3.4015e-01,  2.9286e-01,  9.2406e-02,\n",
      "          2.0610e-01,  5.6000e-01, -2.3330e-01, -3.7790e-01,  5.6869e-02,\n",
      "         -2.8994e-01,  5.5865e-02,  5.0869e-01, -1.6175e+00, -8.8125e-05,\n",
      "         -3.9849e-01, -6.3979e-01,  2.6871e-01,  6.4901e-01,  5.0430e-02,\n",
      "          4.4942e-01,  6.5093e-01,  1.0977e+00, -3.4353e-02, -1.1730e-01,\n",
      "          5.5361e-01,  2.3405e-01,  2.7124e-01, -1.5202e-01,  2.0176e-01,\n",
      "         -7.1511e-01,  5.1407e-01, -6.4702e-01,  7.7714e-01, -1.6816e-02,\n",
      "         -5.7496e-02,  6.1448e-01, -6.4909e-01, -9.7823e-02, -2.2919e-01,\n",
      "         -2.8184e-01, -1.1232e+00, -6.0883e-01, -5.7645e-01, -4.8298e-01,\n",
      "          2.5766e-01,  3.0603e-01,  2.0415e-01,  2.1802e-01,  1.0739e+00,\n",
      "         -2.6343e-01, -8.8048e-02,  4.1755e-01, -2.6182e-02, -1.0608e+00,\n",
      "         -6.7223e-01, -1.1521e+00, -2.0375e-01, -6.9134e-01,  3.2708e-01,\n",
      "          1.1731e+00, -1.5912e-01,  1.7518e-01, -4.5375e-01, -1.9557e-01,\n",
      "         -5.2962e-01, -1.9617e-02,  6.0603e-01,  3.7682e-01, -7.9225e-02,\n",
      "         -3.7474e-01,  2.8441e-02, -3.0465e-01,  1.2729e-01,  3.2005e-01,\n",
      "         -4.3120e-01,  7.4947e-02, -1.0010e+00,  8.5434e-01,  3.9379e-01,\n",
      "          3.6858e-01,  1.2676e-01, -8.7740e-01, -9.2263e-02,  2.2555e-01,\n",
      "         -4.1304e-01, -2.1161e-01, -2.6458e-01,  9.6762e-01, -3.9813e-03,\n",
      "         -1.2653e+00,  3.7584e-01,  6.3722e-01,  2.4996e-01, -7.8227e-01,\n",
      "          3.6158e-02, -1.2544e-02, -6.5246e-01, -3.0663e-02, -4.9310e-01,\n",
      "          2.5479e-01, -1.6056e-01, -8.2981e-02, -1.1907e-01, -7.8331e-02,\n",
      "          3.1164e-01, -1.3109e-01, -1.9844e-01, -1.0170e+00, -1.8747e-01,\n",
      "         -3.4046e-01, -9.6616e-01,  4.9729e-02,  5.3955e-01,  3.2118e-01,\n",
      "          2.5754e-01,  2.9344e-01, -3.2682e-01,  1.3040e-01, -5.6076e-01,\n",
      "         -7.3505e-02, -1.0951e-02, -4.2166e-01, -8.2809e-01, -5.1883e-01,\n",
      "         -8.3111e-01, -1.1903e+00,  2.4882e-02, -4.7838e-01,  5.4159e-01,\n",
      "          2.0509e-01, -1.2677e-01,  3.7908e-01,  5.4838e-01,  3.2568e-01,\n",
      "          4.7082e-01, -7.4575e-01, -3.5083e-01, -6.5656e-01,  1.7549e-02,\n",
      "         -2.8272e-01, -1.5156e-01,  5.0851e-01, -2.6971e-01,  9.3171e-01,\n",
      "          1.9608e-01,  1.1768e-01, -1.0748e+00, -4.8374e-01,  5.0276e-02,\n",
      "         -4.3687e-02, -1.1023e+00, -6.1458e-01, -2.4491e-01, -8.9198e-01,\n",
      "          1.8100e-01, -8.6953e-01, -1.3721e-01,  6.7005e-01, -3.7988e-01,\n",
      "         -1.8232e-01, -1.3514e-02,  7.4111e-01, -6.3791e-01, -1.1311e+00,\n",
      "         -3.8666e-01,  7.1022e-01,  1.9495e-01, -4.5884e-01, -2.8242e-01,\n",
      "          2.7812e-01,  7.6487e-02, -3.1508e-01,  6.7156e-03,  8.9059e-01,\n",
      "         -5.5257e-01, -2.8035e-01,  4.6573e-01, -6.6895e-01,  8.4830e-01,\n",
      "         -3.3834e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[tensor([[[-0.1639, -0.6865,  0.5415,  0.1691, -0.6200,  0.7526,  0.9388,\n",
      "          -0.5667, -0.8614,  0.8132, -0.8183, -0.8598,  0.6027,  0.8826,\n",
      "          -0.8263,  0.3904,  0.9686,  0.6560,  0.8831, -0.0528, -0.8488,\n",
      "           0.0030, -0.0173, -0.7997,  0.6992, -0.8827, -0.5077, -0.8418,\n",
      "           0.8318, -0.8483,  0.9486, -0.4501, -0.9374,  0.7316,  0.9100,\n",
      "           0.8698, -0.3231, -0.6904, -0.0650, -0.7164,  0.9677, -0.8672,\n",
      "           0.4664,  0.5913, -0.9026,  0.7336, -0.0081,  0.3268,  0.9063,\n",
      "           0.2192, -0.4403,  0.1070,  0.0075,  0.8772,  0.2504, -0.9253,\n",
      "          -0.9752, -0.9931,  0.2610,  0.9294, -0.9133,  0.6412,  0.7705,\n",
      "          -0.6019, -0.1276,  0.8765, -0.9154,  0.9506,  0.4111, -0.2063,\n",
      "          -0.8881,  0.4233, -0.8470, -0.0650,  0.3851, -0.9114, -0.4850,\n",
      "           0.2176,  0.5902, -0.9546, -0.1241,  0.7554,  0.8566,  0.2832,\n",
      "          -0.9765, -0.1993,  0.8729, -0.8877,  0.0890, -0.2772,  0.2997,\n",
      "           0.4130,  0.1078,  0.9672,  0.6060,  0.6838, -0.9653,  0.2808,\n",
      "           0.6252,  0.5045, -0.4343, -0.1990, -0.2120, -0.4634, -0.8141,\n",
      "           0.6991,  0.8329,  0.3960,  0.8436, -0.5037, -0.5459,  0.0120,\n",
      "          -0.6771,  0.9366,  0.9109, -0.9985, -0.7336, -0.1871,  0.2567,\n",
      "          -0.7882, -0.6954,  0.8908,  0.8853, -0.7932,  0.9906, -0.5904,\n",
      "           0.7992, -0.0540,  0.2196,  0.7999,  0.1476, -0.5514,  0.0405,\n",
      "           0.5414, -0.1458,  0.1697,  0.2499, -0.4912, -0.9265, -0.1233,\n",
      "          -0.2900,  0.5823,  0.3098,  0.9018,  0.7487,  0.9262,  0.5859,\n",
      "           0.9113,  0.6282,  0.2506,  0.1500,  0.7914, -0.4002, -0.9593,\n",
      "          -0.3501,  0.5037,  0.4610,  0.4855,  0.7035,  0.9453, -0.9616,\n",
      "          -0.8847, -0.7768,  0.9802, -0.3532,  0.1381,  0.4120,  0.6641,\n",
      "          -0.7892,  0.1078,  0.9780, -0.3122, -0.4784,  0.4848,  0.9770,\n",
      "          -0.2461,  0.9184,  0.2606, -0.7651, -0.2406, -0.3451,  0.8514,\n",
      "           0.7999, -0.9429, -0.7222, -0.3495, -0.5162, -0.9400,  0.3437,\n",
      "          -0.6371,  0.6461,  0.9648,  0.6859, -0.9531,  0.7652,  0.6046,\n",
      "           0.9687, -0.0121, -0.9340,  0.8649, -0.9522,  0.1439,  0.5502,\n",
      "          -0.8468, -0.3068,  0.0618, -0.4637,  0.3422,  0.5056, -0.6984,\n",
      "          -0.3257, -0.6459, -0.8679, -0.0142, -0.4897, -0.3098,  0.7761,\n",
      "           0.9147, -0.8675,  0.7241,  0.7278, -0.6964,  0.9109, -0.8681,\n",
      "           0.0224, -0.3639, -0.2057,  0.5658, -0.6134,  0.8356, -0.2468,\n",
      "          -0.2559, -0.9058,  0.1150,  0.4617, -0.8592, -0.9739,  0.9273,\n",
      "           0.6848, -0.8141, -0.7176, -0.1647,  0.2402, -0.5330, -0.5189,\n",
      "           0.0552, -0.8387,  0.6248, -0.7116, -0.0346, -0.6250, -0.7972,\n",
      "          -0.2216,  0.5018, -0.9058, -0.7105]]], device='cuda:0',\n",
      "       grad_fn=<IndexSelectBackward0>), tensor([[[-2.3974e-01, -9.8681e-01,  6.7630e-01, -9.5958e-01, -9.2060e-01,\n",
      "           8.8240e-01,  3.5135e-01, -7.8611e-01,  4.2270e-01,  3.5744e-01,\n",
      "           2.6022e-02,  2.2995e-02,  6.7759e-01,  5.3108e-01, -9.1240e-01,\n",
      "           4.7161e-01,  8.8212e-01, -9.3426e-01,  9.2525e-01, -9.9347e-01,\n",
      "          -2.5061e-01,  6.4216e-01, -7.5575e-01, -4.7447e-01, -6.6795e-01,\n",
      "          -8.5701e-01, -8.0970e-01, -9.4492e-01,  2.2550e-01,  6.5638e-01,\n",
      "          -5.1814e-03,  8.6030e-01, -5.2376e-01, -9.7594e-01, -9.5523e-01,\n",
      "           7.7195e-01, -5.7166e-01,  6.3068e-01, -1.4181e-01,  8.3623e-01,\n",
      "          -9.9337e-01,  9.4020e-01, -3.9841e-02, -9.3449e-01,  9.7449e-01,\n",
      "          -9.7258e-01,  9.1256e-01, -6.6987e-01, -8.5900e-01, -1.1276e-01,\n",
      "           3.7094e-01,  8.9835e-01, -6.1873e-01, -2.4736e-01,  9.2783e-02,\n",
      "           8.6251e-02, -7.6560e-01, -2.8882e-01, -2.9819e-01, -1.5613e-01,\n",
      "          -9.8863e-01, -7.1024e-01, -9.3768e-01, -2.6605e-01,  6.9588e-01,\n",
      "           9.7458e-01, -7.9107e-01,  9.3842e-01, -2.4599e-01, -9.4907e-01,\n",
      "           6.2309e-01,  9.7125e-01,  4.4460e-01,  9.9306e-01,  1.5889e-01,\n",
      "          -8.6860e-01,  9.9837e-01,  5.8739e-01,  8.4194e-01,  9.3616e-01,\n",
      "           3.4940e-01, -9.5913e-01,  1.0743e-01, -5.5915e-01,  7.4834e-01,\n",
      "          -7.9596e-01, -2.8932e-01,  5.9678e-02, -8.4424e-01, -5.1881e-01,\n",
      "          -3.2002e-01, -4.1734e-01,  9.6770e-01, -8.2544e-01,  3.3453e-01,\n",
      "          -8.1640e-01, -9.9069e-01,  8.7060e-01, -5.2825e-01, -9.3253e-01,\n",
      "          -9.7230e-01,  8.1496e-01, -5.5277e-01, -2.8559e-01,  2.4765e-01,\n",
      "          -7.9084e-01,  9.1208e-01,  4.0865e-01,  4.2467e-01,  8.2724e-01,\n",
      "           8.7229e-01, -7.2688e-01, -9.0787e-01, -3.8922e-01,  7.5082e-01,\n",
      "          -5.6353e-01, -8.6544e-01,  9.0556e-01,  2.6334e-01,  4.1943e-01,\n",
      "          -4.9821e-01,  5.3222e-01, -4.5254e-01, -7.9838e-01, -9.4597e-01,\n",
      "           2.0649e-01, -8.2734e-01, -3.3182e-01,  2.4892e-01, -9.1152e-01,\n",
      "           2.1813e-01, -5.8206e-01,  7.1512e-01,  9.5823e-01,  4.2829e-01,\n",
      "           7.7067e-01, -7.2721e-01,  8.1109e-01,  8.2612e-01, -4.9921e-01,\n",
      "           1.0812e-02, -9.2404e-01,  3.5462e-01,  2.3124e-04, -5.1692e-01,\n",
      "           3.1848e-01, -7.9852e-01,  3.1177e-01,  7.3928e-01,  8.9857e-01,\n",
      "           8.5191e-01,  3.0407e-01, -9.8777e-01,  9.8636e-01,  9.2227e-01,\n",
      "           9.3191e-01, -1.3202e-01,  1.3830e-01,  7.4589e-01,  1.3651e-01,\n",
      "           9.2566e-01, -1.7455e-02, -6.4859e-01,  5.7378e-01,  1.4119e-01,\n",
      "           4.9700e-01,  4.6859e-01,  6.3288e-01, -8.5818e-01,  6.9426e-01,\n",
      "           7.2477e-01, -5.9788e-01,  5.6027e-01,  6.9023e-01, -7.6051e-01,\n",
      "           9.8482e-01,  1.0640e-01, -3.8313e-01,  9.4959e-01,  7.6401e-01,\n",
      "           5.6044e-01, -9.8157e-01,  5.5496e-01, -6.4586e-01, -9.4872e-01,\n",
      "           6.3716e-01, -4.7020e-01,  2.6562e-01,  4.2903e-01, -8.2537e-01,\n",
      "           1.2236e-01, -7.6200e-01,  9.8300e-01,  8.2564e-01,  6.4214e-01,\n",
      "           3.6928e-01,  6.5293e-01, -6.2934e-01,  9.1311e-01,  5.4123e-01,\n",
      "          -6.2811e-01, -1.9315e-01,  5.3851e-02, -9.9339e-01, -9.7601e-01,\n",
      "          -4.5466e-02, -3.7282e-01,  9.9726e-01, -9.0612e-01,  2.6602e-01,\n",
      "           9.8560e-01,  9.4587e-01, -8.7324e-01, -4.5562e-01,  8.2596e-01,\n",
      "          -1.5444e-01, -3.1197e-01, -6.8804e-01, -9.2392e-01,  7.7412e-01,\n",
      "          -8.6502e-01,  5.8529e-01,  2.0828e-01, -1.8125e-01,  9.1206e-01,\n",
      "          -2.9849e-01,  7.6742e-01,  8.0877e-01, -7.0280e-01,  8.0281e-01,\n",
      "           9.0220e-01,  9.1949e-01,  9.4287e-01,  9.1085e-01,  3.3354e-01,\n",
      "          -4.4011e-01,  1.0842e-01, -6.5009e-01, -4.1421e-02, -9.3935e-01,\n",
      "          -3.4120e-01,  7.8322e-01, -8.0222e-01,  8.5364e-01, -4.3252e-01,\n",
      "           9.3987e-01,  3.0108e-01, -8.7217e-01,  9.7070e-01, -7.6123e-01,\n",
      "           9.6389e-01, -5.1668e-01, -8.8871e-01, -3.5390e-01,  6.0096e-01,\n",
      "           9.7335e-01]],\n",
      "\n",
      "        [[ 5.5384e-01,  3.3513e-01,  5.5631e-01, -7.5395e-01,  3.5667e-01,\n",
      "          -6.3967e-01, -4.5649e-01, -5.0902e-02,  3.3705e-01, -5.1250e-01,\n",
      "          -4.3828e-01,  7.9034e-01, -5.9193e-01, -7.2227e-01,  1.0450e-01,\n",
      "          -6.4427e-01, -8.1107e-01,  1.2649e-01, -9.7606e-01,  6.8988e-01,\n",
      "           5.4743e-01,  2.6854e-01,  3.4871e-01,  3.4096e-01,  8.4457e-01,\n",
      "           7.0587e-01,  7.9242e-01,  3.2785e-01,  2.6094e-01, -8.1838e-01,\n",
      "           8.5399e-01,  9.3194e-01, -9.4432e-01, -8.4121e-01,  2.8578e-01,\n",
      "           6.7940e-01, -8.5388e-01, -3.1134e-01, -8.5342e-03,  1.5340e-01,\n",
      "           1.4342e-01,  1.9397e-01, -9.7983e-01, -9.2993e-01,  6.9995e-01,\n",
      "          -8.6574e-02,  3.5822e-01,  5.6806e-01,  1.8072e-01,  9.2234e-01,\n",
      "          -6.7450e-01,  9.4204e-01,  2.6833e-01,  2.3924e-01, -5.0141e-01,\n",
      "           5.9379e-01,  1.7578e-01, -7.8963e-01,  2.6245e-01, -8.2984e-01,\n",
      "           4.5895e-01,  1.3305e-01, -3.7073e-01, -4.6242e-01,  8.9645e-01,\n",
      "           2.7810e-01,  7.8300e-01,  6.0604e-01, -2.8749e-01,  8.6243e-01,\n",
      "          -9.7756e-01,  4.3514e-01,  4.0141e-01, -5.9372e-01,  8.4819e-01,\n",
      "           3.8214e-01,  5.4879e-01, -6.0315e-01, -5.7855e-01, -9.1923e-01,\n",
      "          -3.5385e-01, -8.5052e-01,  7.3527e-01,  8.0141e-01, -5.4498e-01,\n",
      "           7.9949e-01, -7.2429e-01,  9.1442e-01,  9.9228e-01,  7.1364e-02,\n",
      "          -3.9754e-01,  8.2358e-01,  7.0420e-01,  9.3586e-01, -5.8537e-01,\n",
      "          -2.4734e-01,  2.2662e-01, -4.2815e-01,  9.4760e-01,  5.8920e-01,\n",
      "           1.0292e-01,  6.5455e-01, -4.8748e-01,  7.4650e-01,  1.7253e-01,\n",
      "          -4.7814e-01,  8.5560e-01,  1.3915e-01,  3.8176e-01,  8.4356e-01,\n",
      "          -8.2830e-01, -3.7208e-01,  9.6665e-01,  6.0230e-01,  1.4853e-01,\n",
      "          -7.2748e-01, -6.0636e-01, -7.3637e-01,  7.8062e-01,  3.2371e-01,\n",
      "          -5.3680e-01,  6.0618e-01,  1.3710e-01, -4.3435e-01, -1.8324e-01,\n",
      "           2.9121e-01,  6.2137e-01, -5.3098e-01, -1.9361e-02, -5.7183e-01,\n",
      "          -5.5894e-02, -4.7947e-01,  8.1010e-01, -3.4693e-01, -7.7045e-01,\n",
      "           9.9126e-01,  4.6217e-01,  8.5935e-01,  7.6139e-02, -8.0698e-01,\n",
      "          -1.9097e-01,  7.5587e-01,  1.6442e-01, -6.9759e-01, -2.6697e-01,\n",
      "          -8.7249e-01, -7.5106e-01, -7.3459e-01,  3.1078e-01,  8.1534e-01,\n",
      "           8.9550e-01, -9.8580e-01,  9.1381e-01, -8.5855e-01,  5.7479e-01,\n",
      "           2.5990e-01, -3.6457e-01,  2.7270e-01, -6.9501e-01, -2.0140e-01,\n",
      "          -7.4277e-01, -4.4022e-01,  7.3290e-01, -3.6011e-01,  8.1149e-01,\n",
      "          -2.3367e-01,  7.6619e-01, -7.6620e-01, -2.0634e-01,  4.9325e-01,\n",
      "           5.7030e-02,  6.7018e-01, -1.8313e-02,  7.0400e-01, -4.4853e-02,\n",
      "           1.1922e-01,  4.6386e-01, -8.5053e-01,  8.2001e-01, -6.2021e-01,\n",
      "          -1.4763e-01,  9.0854e-01,  5.3734e-01, -1.0410e-01,  9.8801e-01,\n",
      "          -8.9947e-01,  7.2520e-01, -1.4195e-01, -6.9988e-01,  9.7201e-01,\n",
      "           9.0065e-04, -3.4002e-01, -5.8560e-01, -8.8303e-01,  3.6297e-02,\n",
      "          -6.6814e-01,  7.6365e-01,  8.0193e-01,  6.8912e-01, -7.8166e-02,\n",
      "          -6.3731e-01, -6.1547e-02,  6.8682e-01,  2.8969e-01, -6.5371e-02,\n",
      "          -2.7211e-01,  9.3662e-01, -9.1348e-01,  9.1179e-01,  7.8824e-01,\n",
      "           1.1782e-01, -6.0033e-01, -7.3867e-01,  6.0472e-01, -8.1267e-01,\n",
      "           3.8733e-01, -1.9566e-01,  2.5355e-01, -6.8032e-01, -2.9753e-01,\n",
      "           8.0536e-01, -4.1799e-01,  1.1663e-01, -9.6382e-01,  9.9169e-01,\n",
      "          -7.8113e-01, -5.7469e-01,  8.2127e-01,  3.8440e-01, -9.8995e-01,\n",
      "           8.7176e-01, -3.8576e-01, -6.8345e-02,  4.8721e-01,  5.6408e-02,\n",
      "           1.3261e-02,  7.9305e-01, -9.6203e-01, -5.3767e-01, -4.2241e-01,\n",
      "          -2.4088e-01,  5.5250e-01, -9.4954e-01,  6.4341e-01, -9.6868e-01,\n",
      "           5.4143e-02,  1.8871e-01, -1.5079e-01,  2.1995e-01,  5.4813e-01,\n",
      "          -5.0992e-01,  3.8159e-01,  2.0141e-01, -8.8534e-01, -8.3401e-01,\n",
      "          -9.4693e-01]]], device='cuda:0', grad_fn=<IndexSelectBackward0>), tensor([[[ 0.5123, -0.1846, -0.1047,  0.7392, -0.7910,  0.9596, -0.4776,\n",
      "          -0.7983,  0.9333, -0.5010, -0.1367,  0.9069, -0.6251, -0.0827,\n",
      "           0.4660,  0.1328,  0.9215, -0.1119,  0.4296,  0.9912,  0.6733,\n",
      "          -0.7636,  0.9166, -0.4962,  0.6257,  0.0680, -0.7399,  0.0878,\n",
      "          -0.0749,  0.9360, -0.6218, -0.9923, -0.1562, -0.2425,  0.6560,\n",
      "          -0.3592, -0.8267, -0.0913, -0.9408, -0.3518,  0.9520,  0.8687,\n",
      "          -0.8019,  0.3269,  0.4762,  0.1916,  0.9036,  0.9304, -0.4245,\n",
      "           0.9528,  0.6137,  0.3619, -0.7611,  0.6997, -0.8146,  0.2616,\n",
      "          -0.0978,  0.8597, -0.8931,  0.9848, -0.7640, -0.7464, -0.9863,\n",
      "          -0.9901,  0.7327, -0.4333, -0.7171, -0.8785, -0.0452,  0.5150,\n",
      "           0.1277, -0.7506,  0.7870, -0.5765, -0.7103,  0.7970,  0.9870,\n",
      "           0.9908, -0.4917, -0.9814, -0.4609,  0.6018,  0.8922, -0.9642,\n",
      "          -0.0357,  0.9841, -0.5863, -0.0762, -0.8021, -0.9801, -0.5530,\n",
      "          -0.9101,  0.9341,  0.3230, -0.8351,  0.3946,  0.8849, -0.6623,\n",
      "          -0.9956,  0.8878,  0.1267,  0.0197,  0.9605, -0.9004,  0.7987,\n",
      "           0.6282,  0.5723, -0.9952, -0.0785,  0.0934,  0.9570,  0.9626,\n",
      "           0.9961,  0.8815,  0.7085, -0.2120, -0.9272,  0.8587,  0.6336,\n",
      "           0.1106, -0.8459,  0.7143,  0.7007, -0.6789,  0.9024,  0.8823,\n",
      "          -0.5132,  0.9610,  0.9574,  0.0676, -0.9320, -0.5720,  0.4552,\n",
      "          -0.3905,  0.8669, -0.9581, -0.8647,  0.3193,  0.9432, -0.7996,\n",
      "          -0.6961, -0.7216,  0.9892,  0.5746,  0.9764,  0.1929, -0.9443,\n",
      "          -0.9669, -0.3597, -0.8815, -0.8203,  0.9734,  0.8727,  0.8523,\n",
      "          -0.8857, -0.6601,  0.8837,  0.8916, -0.2157, -0.9811, -0.4098,\n",
      "           0.8268,  0.3537,  0.9490, -0.9698, -0.3032,  0.5837, -0.5634,\n",
      "          -0.8951, -0.0714, -0.6176, -0.4040, -0.9344,  0.4574,  0.5029,\n",
      "           0.9023,  0.8393, -0.0152,  0.2900,  0.9248,  0.3210,  0.7794,\n",
      "           0.8791, -0.9168,  0.2757, -0.7222, -0.9297, -0.9728, -0.4618,\n",
      "           0.8766,  0.1161, -0.9151,  0.8826, -0.6271, -0.9101,  0.8115,\n",
      "           0.7845,  0.7650,  0.9964,  0.5850, -0.8660,  0.3379,  0.8387,\n",
      "          -0.6710,  0.1649, -0.6623, -0.2972, -0.6176,  0.9612, -0.9793,\n",
      "          -0.8518,  0.2421, -0.5960, -0.9597, -0.3649,  0.6025,  0.9276,\n",
      "          -0.3340, -0.2009,  0.4597,  0.5530,  0.1361, -0.5734,  0.3557,\n",
      "          -0.8200, -0.7099, -0.7505,  0.6098,  0.5324,  0.4700,  0.0748,\n",
      "           0.7054,  0.8283,  0.2390,  0.8884, -0.7158, -0.7709, -0.2664,\n",
      "          -0.4275,  0.7710,  0.4369,  0.2588,  0.7351, -0.8594, -0.0969,\n",
      "          -0.2251, -0.1404, -0.8642, -0.9619, -0.9295,  0.9679, -0.3702,\n",
      "          -0.9703,  0.8836, -0.7600,  0.1987]],\n",
      "\n",
      "        [[-0.1143,  0.4216, -0.9098, -0.2658, -0.9516,  0.1908, -0.9246,\n",
      "           0.0447, -0.2768,  0.7577,  0.1860, -0.1693, -0.7346, -0.9376,\n",
      "          -0.9758,  0.2194, -0.0400, -0.0500,  0.8936,  0.1488,  0.1266,\n",
      "           0.8183, -0.9651,  0.1783, -0.1865,  0.2573,  0.9353, -0.3425,\n",
      "          -0.9462,  0.1516, -0.7466,  0.0505, -0.7888,  0.7690, -0.3987,\n",
      "           0.3603, -0.7879,  0.8988, -0.9068, -0.9523, -0.1777,  0.8876,\n",
      "          -0.9130, -0.3217,  0.6934,  0.6989, -0.6797, -0.3382, -0.2307,\n",
      "          -0.2721, -0.8353, -0.8805, -0.9994,  0.6337,  0.3673, -0.8159,\n",
      "          -0.2693,  0.8553,  0.5468, -0.7073,  0.4709,  0.8457,  0.1100,\n",
      "           0.3939,  0.6474,  0.5340, -0.6958, -0.3299,  0.8469,  0.0117,\n",
      "          -0.9796,  0.1460, -0.8703,  0.1421, -0.5330, -0.0406,  0.2159,\n",
      "           0.7054,  0.9379, -0.4147,  0.1943, -0.4473,  0.8367,  0.8948,\n",
      "          -0.4523,  0.2600,  0.3124,  0.8604, -0.0577, -0.8802, -0.1827,\n",
      "           0.8667, -0.1705, -0.5276, -0.4426, -0.8796,  0.5265,  0.9059,\n",
      "           0.3981, -0.7524,  0.9196,  0.7946,  0.4807, -0.8222, -0.8815,\n",
      "          -0.6182, -0.4615, -0.3958, -0.1368,  0.8119, -0.6791,  0.4876,\n",
      "          -0.6636, -0.2214,  0.6644, -0.8113, -0.6270, -0.8298, -0.9699,\n",
      "          -0.8778, -0.6020,  0.4019,  0.2314,  0.9763,  0.8001, -0.5471,\n",
      "           0.1301, -0.9982,  0.8925,  0.5647,  0.8836, -0.1300, -0.8225,\n",
      "           0.8266,  0.2523, -0.8442, -0.9376, -0.7527, -0.2502,  0.8946,\n",
      "          -0.8852,  0.5856,  0.5465,  0.3699, -0.8199,  0.3420, -0.1009,\n",
      "           0.7986,  0.9614,  0.1589,  0.1523,  0.1324,  0.6690, -0.6747,\n",
      "          -0.2516, -0.3888, -0.7394,  0.6520,  0.9115, -0.7182,  0.7326,\n",
      "          -0.6925,  0.8487,  0.9082, -0.3273,  0.4725,  0.8810, -0.9245,\n",
      "           0.6507,  0.0358,  0.7485,  0.6141,  0.6638,  0.6092,  0.8217,\n",
      "           0.2386,  0.6180,  0.3922,  0.5125, -0.0031,  0.4720,  0.8387,\n",
      "           0.6485,  0.7674,  0.6921, -0.2627,  0.1488,  0.0363,  0.9741,\n",
      "           0.7476,  0.7841,  0.8321, -0.9282, -0.8037, -0.8103,  0.8261,\n",
      "           0.7008,  0.2019, -0.4660, -0.3942,  0.8845,  0.7006,  0.9546,\n",
      "           0.9266, -0.8900,  0.0642,  0.9287, -0.9460,  0.9413,  0.8913,\n",
      "          -0.5170, -0.4653,  0.2890,  0.5820, -0.1687, -0.9245, -0.8574,\n",
      "          -0.9979, -0.1106,  0.1782, -0.0268, -0.4971, -0.7939, -0.2971,\n",
      "          -0.5230, -0.9744, -0.9660, -0.4897,  0.1280, -0.4480, -0.8783,\n",
      "           0.3008, -0.2781, -0.3061,  0.5039,  0.7531,  0.1977,  0.4261,\n",
      "          -0.8461, -0.6256, -0.9619, -0.8524,  0.4963, -0.8066, -0.7787,\n",
      "           0.8029,  0.6024, -0.9752,  0.8405,  0.3899,  0.6957,  0.2881,\n",
      "           0.6479,  0.8582, -0.8562, -0.4827]],\n",
      "\n",
      "        [[-0.0166,  0.3281, -0.9514, -0.3998, -0.6573, -0.9451,  0.6940,\n",
      "           0.2397, -0.5757,  0.0625, -0.9322,  0.6465, -0.4580, -0.0387,\n",
      "           0.4512,  0.9368,  0.2457, -0.8674,  0.6202,  0.9528, -0.2173,\n",
      "          -0.3735,  0.4201,  0.8392, -0.3204,  0.3601, -0.6490, -0.0131,\n",
      "           0.5977,  0.4859,  0.8378, -0.4124,  0.4863,  0.9370,  0.6000,\n",
      "           0.6256, -0.0908,  0.2730, -0.8176, -0.4747,  0.5065,  0.9994,\n",
      "           0.6531, -0.8062,  0.2003,  0.6801, -0.1207, -0.8775, -0.7213,\n",
      "          -0.7776, -0.3316,  0.5127, -0.5259,  0.2276, -0.9580, -0.8499,\n",
      "          -0.9489,  0.8920,  0.9009, -0.1439, -0.2584, -0.5124,  0.9929,\n",
      "          -0.6130,  0.7509, -0.8987, -0.8824, -0.9145, -0.8144, -0.9791,\n",
      "           0.9665,  0.2876,  0.9593,  0.7784,  0.9540, -0.5637, -0.8952,\n",
      "           0.6495, -0.0035,  0.5636,  0.4812,  0.9002, -0.2694, -0.8056,\n",
      "          -0.0132, -0.8415,  0.0486,  0.4746,  0.6832,  0.7413,  0.6011,\n",
      "           0.6288, -0.8394,  0.3215,  0.8064,  0.9312,  0.8747,  0.1753,\n",
      "          -0.7065, -0.4128,  0.8913,  0.9064, -0.9315, -0.1943, -0.1845,\n",
      "          -0.5890,  0.5947, -0.9384, -0.2394,  0.1893, -0.4099,  0.1445,\n",
      "          -0.5891,  0.6622, -0.4613,  0.8158, -0.8456, -0.8190, -0.9499,\n",
      "           0.9311, -0.7010,  0.9850, -0.9745,  0.6814,  0.3718,  0.3907,\n",
      "           0.4725,  0.3796,  0.8532,  0.9104,  0.2638,  0.9051, -0.8387,\n",
      "          -0.3863,  0.5542,  0.1775,  0.4716,  0.8355, -0.8125,  0.3735,\n",
      "           0.1186,  0.6090, -0.9812,  0.9383, -0.6288, -0.9886,  0.9441,\n",
      "           0.6252, -0.3038,  0.9675,  0.5084, -0.4485, -0.2931, -0.5890,\n",
      "           0.9690, -0.7424,  0.8162,  0.0259, -0.8650, -0.2738, -0.7394,\n",
      "          -0.1429, -0.6287,  0.8284, -0.7046, -0.7425, -0.3701,  0.5465,\n",
      "           0.1497, -0.9315,  0.5089, -0.9464, -0.3735,  0.6750,  0.8242,\n",
      "          -0.8283, -0.9923, -0.5944, -0.3734,  0.2895,  0.1361, -0.2931,\n",
      "           0.9846,  0.9368,  0.3426, -0.9053,  0.8456, -0.9383, -0.2738,\n",
      "          -0.3344,  0.1567,  0.8628,  0.1812,  0.5658, -0.2807, -0.8722,\n",
      "          -0.9745, -0.9749,  0.7850, -0.1786, -0.2748,  0.9322, -0.3916,\n",
      "           0.7929,  0.6959,  0.5101, -0.9400, -0.3299, -0.6345, -0.4160,\n",
      "          -0.2210,  0.9897,  0.9415, -0.2890,  0.3495, -0.7526, -0.8384,\n",
      "           0.6501,  0.9186, -0.8994, -0.4298, -0.5485, -0.0656,  0.3869,\n",
      "          -0.0062,  0.2649, -0.2278, -0.4971, -0.6224,  0.7096,  0.3311,\n",
      "           0.3266,  0.5014,  0.7265, -0.8811, -0.4942,  0.9065, -0.7301,\n",
      "          -0.2987,  0.3105, -0.7838,  0.2761, -0.1545,  0.6801, -0.1006,\n",
      "          -0.3787, -0.9228, -0.6956, -0.3280, -0.1037,  0.4841,  0.8806,\n",
      "           0.3735, -0.7413, -0.8563,  0.9676]]], device='cuda:0',\n",
      "       grad_fn=<IndexSelectBackward0>), tensor([[[-0.8729, -0.4093, -0.0542,  ..., -0.8839,  0.7709, -0.9424]],\n",
      "\n",
      "        [[-0.7087,  0.8238,  0.5881,  ..., -0.3693,  0.5905, -0.0559]],\n",
      "\n",
      "        [[ 0.5829, -0.0164,  0.4781,  ...,  0.7776,  0.5296, -0.5584]],\n",
      "\n",
      "        [[ 0.5029, -0.1270, -0.6892,  ...,  0.6499, -0.5147, -0.5324]]],\n",
      "       device='cuda:0', grad_fn=<IndexSelectBackward0>), tensor([[[-0.9357,  0.8180,  0.8201,  ..., -0.6486,  0.2878,  0.5392]],\n",
      "\n",
      "        [[ 0.4373, -0.1336,  0.3513,  ...,  0.1234, -0.1065, -0.0606]],\n",
      "\n",
      "        [[-0.6378, -0.3464,  0.6666,  ..., -0.6366,  0.0922,  0.1955]],\n",
      "\n",
      "        [[-0.6796, -0.0999,  0.0711,  ...,  0.9361, -0.1158,  0.1361]],\n",
      "\n",
      "        [[ 0.2761, -0.1029, -0.3838,  ..., -0.6913,  0.0504, -0.7098]]],\n",
      "       device='cuda:0', grad_fn=<IndexSelectBackward0>)]\n",
      "CLfseously nhes cat anle bbmoace fu mieatoweduat bsportante,]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prevs,ins,outs = dataset[len(dataset)-1]\n",
    "N_prevs = len(prevs)\n",
    "N_currents = len(ins)\n",
    "prevs = prevs.to(device)[None,:]\n",
    "ins = ins.to(device)[None,:]\n",
    "outs = outs.to(device)[None,:]\n",
    "prevs = add_positional_info(prevs)\n",
    "ins = add_positional_info(ins)\n",
    "print(prevs.shape)\n",
    "print(prevs)\n",
    "print(dataset.vec2str(prevs[0,:,0]))\n",
    "print(''.join( str(i) for i in prevs[0,:,1].tolist()[2:]))\n",
    "print(ins.shape)\n",
    "print(ins)\n",
    "print(dataset.vec2str(ins[0,:,0]))\n",
    "print(''.join( str(i) for i in ins[0,:,1].tolist()[2:]))\n",
    "encoder_tensor = encoder(prevs,[N_prevs])\n",
    "print(encoder_tensor.shape)\n",
    "print(encoder_tensor)\n",
    "pred, states = decoder(ins,encoder_tensor,[N_currents])\n",
    "print(states)\n",
    "print(dataset.vec2str(torch.exp(pred).squeeze(0).multinomial(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02b13252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bot(nn.Module):\n",
    "  def __init__(self, encoder, decoder, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    if type(temperature)==float or type(temperature)==int:\n",
    "        temperature = lambda pred,*args,temp=temperature: pred/temp\n",
    "    self.temperature = temperature\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "    self.softmax = nn.Softmax(-1)\n",
    "\n",
    "  def generate_answer(self, inputs, max_length=500):\n",
    "    self.encoder.eval()\n",
    "    self.decoder.eval()\n",
    "    # Convert strings to token IDs.\n",
    "    input_ids = self.ids_from_chars(inputs)\n",
    "    input_ids = input_ids[None,:]\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_ids = add_positional_info(input_ids)\n",
    "    \n",
    "    # Encode input\n",
    "    encoder_tensor = self.encoder(input_ids,[len(inputs)])\n",
    "\n",
    "    # First Run\n",
    "    input_ids = self.ids_from_chars('\\r')\n",
    "    input_ids = input_ids[None,:]\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_ids = add_positional_info(input_ids)\n",
    "    last_positional_info = input_ids[:,-1:,1]\n",
    "    predicted_logits, states = self.decoder(input_ids,encoder_tensor,[1])\n",
    "    \n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    prediction_position = len(inputs)\n",
    "    predicted_logits = self.temperature(predicted_logits,prediction_position)\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_logits = self.softmax(predicted_logits)\n",
    "    predicted_ids = predicted_logits.multinomial(1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids[0])\n",
    "    predicted_chars = list(predicted_chars)\n",
    "    predicted_chars = predicted_chars[0]\n",
    "    if predicted_chars == ' ':\n",
    "        last_positional_info += 1\n",
    "    elif predicted_chars in ['.','!','?']:\n",
    "        last_positional_info *= 0\n",
    "\n",
    "    run = '\\r' + predicted_chars\n",
    "    for _ in range(max_length):\n",
    "        # Consecutive Run\n",
    "        predicted_ids = torch.stack((predicted_ids,last_positional_info),dim=2)\n",
    "        predicted_logits, states = self.decoder(predicted_ids,encoder_tensor,[1],states)\n",
    "\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        prediction_position += 1\n",
    "        predicted_logits = self.temperature(predicted_logits,prediction_position)\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_logits = self.softmax(predicted_logits)\n",
    "        predicted_ids = predicted_logits.multinomial(1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids[0])\n",
    "        predicted_chars = list(predicted_chars)\n",
    "        predicted_chars = predicted_chars[0]\n",
    "        \n",
    "        # Update positional info\n",
    "        if predicted_chars == ' ':\n",
    "            last_positional_info += 1\n",
    "        elif predicted_chars in ['.','!','?']:\n",
    "            last_positional_info *= 0\n",
    "\n",
    "        run = run + predicted_chars\n",
    "        if predicted_chars=='\\n':\n",
    "            break\n",
    "    \n",
    "    if run[-1]!='\\n':\n",
    "        run += '\\n'\n",
    "    \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfa4b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Bot(encoder,decoder,dataset.vec2str,dataset.str2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7632d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\rBastila of the dark places students, but three must be opened like that students of great against them and she jouqued up.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.generate_answer('\\rWhat are you thinking?\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6fe4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='sum') # loss(prob_guess, index_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1cb733e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.5168, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_loss = loss(pred.permute(0,2,1),outs,)\n",
    "mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20a406d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7250e+28, device='cuda:0', grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bc65808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(),amsgrad=True)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(),amsgrad=True)\n",
    "if scheduler_rate=='constant':\n",
    "    lr_func = lambda epoch: 1.\n",
    "elif scheduler_rate=='sqrt':\n",
    "    lr_func = lambda epoch: 1./np.sqrt(1+epoch)\n",
    "elif scheduler_rate=='linear':\n",
    "    lr_func = lambda epoch: 1./(1+epoch)\n",
    "else:\n",
    "    raise Exception('No valid scheduler rate was selected!')\n",
    "encoder_scheduler = optim.lr_scheduler.LambdaLR(encoder_optimizer,lr_func,verbose=True)\n",
    "decoder_scheduler = optim.lr_scheduler.LambdaLR(decoder_optimizer,lr_func,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "194f1dca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations per epoch: 456\n",
      "455 5235.22802734375 Done in min: 0.0 4.663564205169678 19.685901641845703 0.04699861630797386                  \n",
      "0 141.36741280555725 5835.854257684005\n",
      "Output matrix norms:\n",
      "\t 1 1.6145355701446533 7.47815465927124\n",
      "\t 2 2.2233927249908447 8.707744598388672\n",
      "\t 3 2.0216012001037598 8.343022346496582\n",
      "\t 4 2.24212908744812 7.597736358642578\n",
      "\t 5 1.9023208618164062 6.581195831298828\n",
      "\n",
      "\tQuery:\n",
      "Here's the spice - now give me your access card.\n",
      "\n",
      "\tInput:\n",
      "You see? I knew you were the type to answer the door when opportunity knocks! Wait here and I'll be right back with my access card.\n",
      "\tGuess:\n",
      "Oou dte  T jnew wou shre nhe erpe fo sdswer the naor.teon tnportunity eiowks \n",
      "Nest tere!nsd d ml fe aicht?heck.phth me actess.tord.\n",
      "\n",
      "\tGenerate:\n",
      "Not to your test, oxely, with it! I cannot real your investories from this put to pay.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Ah, let's see this power to you! I can't pay again!\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0711e-04.\n",
      "Adjusting learning rate of group 0 to 7.0711e-04.\n",
      "455 4818.4765625 Done in min: 0.0 4.6862473487854 21.896135330200195 0.04636596515774727                        \n",
      "1 141.0522038936615 5392.709155701755\n",
      "Output matrix norms:\n",
      "\t 1 1.6808429956436157 7.747153282165527\n",
      "\t 2 2.2983222007751465 9.060855865478516\n",
      "\t 3 2.1096205711364746 8.699360847473145\n",
      "\t 4 2.3681514263153076 8.051896095275879\n",
      "\t 5 2.0037128925323486 6.996047019958496\n",
      "\n",
      "\tQuery:\n",
      "Well, what happens now?\n",
      "\n",
      "\tInput:\n",
      "That would depend on you, <FullName>. You will either kill me or decide that I may yet benefit my people.\n",
      "\tGuess:\n",
      "What iauld aosen  on tour aFullName>. Hoursoll ant er tnll be of secesedwoet d kiy.lea we eait tu weople.\n",
      "\n",
      "\tGenerate:\n",
      "I have not think about that, hey are geneting skilled. It was one of those children they've gone for dijustant.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Grruptions! But nobody doubt. she was exist for your local as a young hand of the Sith consideradal interrogation. You said nothing of purchase such a facility.\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7735e-04.\n",
      "Adjusting learning rate of group 0 to 5.7735e-04.\n",
      "455 5190.8095703125 Done in min: 0.0 4.7022600173950195 22.33085823059082 0.04601306840777397                   \n",
      "2 141.306955575943 5070.884483471252\n",
      "Output matrix norms:\n",
      "\t 1 1.7424290180206299 8.009589195251465\n",
      "\t 2 2.390629529953003 9.392965316772461\n",
      "\t 3 2.2201881408691406 9.04697322845459\n",
      "\t 4 2.46921706199646 8.489259719848633\n",
      "\t 5 2.0934760570526123 7.470202445983887\n",
      "\n",
      "\tQuery:\n",
      "Disreputable business practices, even more disreputable clients. I've even heard he had dealings with... a Hutt! A Hutt here on Dantooine!\n",
      "\n",
      "\tInput:\n",
      "Now I bet you're wondering if I had any reasons to kill the man, but I tell you I hardly knew him! Saw him once or twice, yes, and I have heard some pretty unkind things about him, but...\n",
      "\tGuess:\n",
      "Wo ,w'drltyou re irrderdng,st I kad hn tteason  Io sell the sin. dut I'khll hou't'cavdly hnow him  IhinLam huee af shice  Ros. mnd y aove geard dumeowlesay pndind hoesgs trout tim. Sut...\n",
      "\n",
      "\tGenerate:\n",
      "I hope not. Let - he's got to meet you and if I find a question. We told your home will before you and save here.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "We can use it and hope we know of a gign in the extinal students, and all right the last you wanted to collect me.\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "455 5184.9482421875 Done in min: 0.0 4.714990615844727 22.719371795654297 0.04123283177614212                   \n",
      "3 141.02332472801208 4793.15427760074\n",
      "Output matrix norms:\n",
      "\t 1 1.7859314680099487 8.25209903717041\n",
      "\t 2 2.460584878921509 9.692710876464844\n",
      "\t 3 2.306887626647949 9.364701271057129\n",
      "\t 4 2.5795140266418457 8.924215316772461\n",
      "\t 5 2.173118829727173 8.01169204711914\n",
      "\n",
      "\tQuery:\n",
      "You're right. Don't worry, you won't feel a thing.\n",
      "\n",
      "\tInput:\n",
      "Do it. Quickly...\n",
      "\tGuess:\n",
      "Do ys.\n",
      "Wuickly, . \n",
      "\tGenerate:\n",
      "I love your own business.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Yes, are we should give you a time possession we could core for him. He nedves the attempt of the Sith Empire. He doesn't keep much.\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4721e-04.\n",
      "Adjusting learning rate of group 0 to 4.4721e-04.\n",
      "455 4962.1767578125 Done in min: 0.0 4.733129978179932 25.213150024414062 0.043041929602622986                  \n",
      "4 141.4726243019104 4521.509609824733\n",
      "Output matrix norms:\n",
      "\t 1 1.8303734064102173 8.497060775756836\n",
      "\t 2 2.5367250442504883 9.986659049987793\n",
      "\t 3 2.4101614952087402 9.678205490112305\n",
      "\t 4 2.667703628540039 9.339520454406738\n",
      "\t 5 2.250204563140869 8.565672874450684\n",
      "\n",
      "\tQuery:\n",
      "Please - I'm only a visitor to Taris, trapped here by your quarantine. I know nothing about the Tarisian underground or your missing Sith uniforms!\n",
      "\n",
      "\tInput:\n",
      "Uniforms? What are they talking about?\n",
      "\tGuess:\n",
      "Agltorms? Shat ere yhey grlking about?\n",
      "\n",
      "\tGenerate:\n",
      "They are all polical guidable by stupid so hard to see, but he hasn't our cullerage eforces? No - old Sunry has returned!\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "I hear the Sith and a way with your help. Please, I'm purchased, however, wouldn't you?\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0825e-04.\n",
      "Adjusting learning rate of group 0 to 4.0825e-04.\n",
      "455 4748.03125 Done in min: 0.0 4.746388912200928 25.801315307617188 0.04781491681933403                         \n",
      "5 141.40312266349792 4250.969048751028\n",
      "Output matrix norms:\n",
      "\t 1 1.8905699253082275 8.75461196899414\n",
      "\t 2 2.6198813915252686 10.282251358032227\n",
      "\t 3 2.50447678565979 9.988490104675293\n",
      "\t 4 2.772186040878296 9.759647369384766\n",
      "\t 5 2.3300395011901855 9.133052825927734\n",
      "\n",
      "\tQuery:\n",
      "Defense is operational. Caution... actuators cannot sustain... malfunction.\n",
      "\n",
      "\tInput:\n",
      "I'll scrap you and take what I can.\n",
      "\tGuess:\n",
      "CDll toaapyfou dsd fhke hhat e san \n",
      "\n",
      "\tGenerate:\n",
      "You can't go.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "There are some things of kolto to be doubled, a bunch of kolto. He could never fight later.\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7796e-04.\n",
      "Adjusting learning rate of group 0 to 3.7796e-04.\n",
      "455 4763.91015625 Done in min: 0.0 4.754120349884033 26.973249435424805 0.037341441959142685                     \n",
      "6 141.40897822380066 3982.1223931563527\n",
      "Output matrix norms:\n",
      "\t 1 1.9360973834991455 9.001092910766602\n",
      "\t 2 2.6963555812835693 10.573320388793945\n",
      "\t 3 2.6003873348236084 10.304091453552246\n",
      "\t 4 2.8629376888275146 10.177600860595703\n",
      "\t 5 2.418041706085205 9.706854820251465\n",
      "\n",
      "\tQuery:\n",
      "\n",
      "\n",
      "\tInput:\n",
      "Greetings, young Padawan. I trust your training goes well.\n",
      "\tGuess:\n",
      "Ioeetings, heung Padawan. A shust you  nriining arvs well \n",
      "\n",
      "\tGenerate:\n",
      "You made a complete protocol and removed what you seek arrival of the Council...\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Strange. Perhaps she barages to violent, the problems here had an advance to the attement. We came and going to be tolerand.\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5355e-04.\n",
      "Adjusting learning rate of group 0 to 3.5355e-04.\n",
      "455 3159.040771484375 Done in min: 0.0 4.764488220214844 28.097293853759766 0.0486186258494854                   \n",
      "7 141.70082712173462 3711.5739082202576\n",
      "Output matrix norms:\n",
      "\t 1 1.986878514289856 9.254068374633789\n",
      "\t 2 2.777536630630493 10.868542671203613\n",
      "\t 3 2.6983513832092285 10.61763858795166\n",
      "\t 4 2.9586410522460938 10.59355354309082\n",
      "\t 5 2.5103726387023926 10.285009384155273\n",
      "\n",
      "\tQuery:\n",
      "I agree with Mission. I swore a life-debt to the person you are, not to the person you were.\n",
      "\n",
      "\tInput:\n",
      "Big Z and I will stick by you. We owe you our lives; we won't desert you now!\n",
      "\tGuess:\n",
      "Neg Z snd w hosl ceack wy your Wh wne you onr sites; ye win't destrt sou how,\n",
      "\n",
      "\tGenerate:\n",
      "Don't forget I'm her one more, too. I joined the Selkath gover Republics, and all of us. It's easier the more.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Czerka Corporation has assess or sure we could stay on you, and remain friends for the prototype very dangerous.\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3333e-04.\n",
      "Adjusting learning rate of group 0 to 3.3333e-04.\n",
      "455 4029.800537109375 Done in min: 0.0 4.775770664215088 29.07974624633789 0.04975837841629982                   \n",
      "8 141.27377772331238 3444.3102095754525\n",
      "Output matrix norms:\n",
      "\t 1 2.036065101623535 9.509123802185059\n",
      "\t 2 2.8532001972198486 11.165053367614746\n",
      "\t 3 2.7828450202941895 10.928359985351562\n",
      "\t 4 3.0517618656158447 11.010416030883789\n",
      "\t 5 2.6067557334899902 10.86889934539795\n",
      "\n",
      "\tQuery:\n",
      "\n",
      "\n",
      "\tInput:\n",
      "You again? Why do you keep bothering me?\n",
      "\tGuess:\n",
      "You nrain? Wha do you bnep juthering me?\n",
      "\n",
      "\tGenerate:\n",
      "Escape pod is friending over are tonggiverative. I hear the risks of the other 'gload's big destricted.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He could disable her patrols and wares no other patrons. They've seen all their it's trembling by what everything does.\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1623e-04.\n",
      "Adjusting learning rate of group 0 to 3.1623e-04.\n",
      "455 3309.987060546875 Done in min: 0.0 4.785679340362549 30.22257423400879 0.05482279136776924                  \n",
      "9 141.71942019462585 3184.319863838062\n",
      "Output matrix norms:\n",
      "\t 1 2.079406261444092 9.758011817932129\n",
      "\t 2 2.9264345169067383 11.452098846435547\n",
      "\t 3 2.878246784210205 11.241556167602539\n",
      "\t 4 3.1435506343841553 11.420437812805176\n",
      "\t 5 2.6981253623962402 11.429326057434082\n",
      "\n",
      "\tQuery:\n",
      "Last question! You're about to die. Do you pass on your knowledge to your apprentice to make him stronger... or do you use your last breath to strike at your enemies?\n",
      "\n",
      "\tInput:\n",
      "Neither. A true Sith never dies.\n",
      "\tGuess:\n",
      "Yovther \n",
      "Pltrue Jith Aover died. \n",
      "\tGenerate:\n",
      "Nothing. NIG\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "I told you there we may walk in the ways of the Sith. Followed me on Manaan - and victory would attack them from his programming.\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0151e-04.\n",
      "Adjusting learning rate of group 0 to 3.0151e-04.\n",
      "455 3256.814208984375 Done in min: 0.0 4.791506290435791 30.138620376586914 0.0492466539144516                   \n",
      "10 141.2878715991974 2930.203918992427\n",
      "Output matrix norms:\n",
      "\t 1 2.1250011920928955 10.01157283782959\n",
      "\t 2 3.012514591217041 11.745115280151367\n",
      "\t 3 2.9711148738861084 11.554323196411133\n",
      "\t 4 3.2356715202331543 11.82591724395752\n",
      "\t 5 2.7995901107788086 11.987765312194824\n",
      "\n",
      "\tQuery:\n",
      "What? You again? Look, are you here to race or aren't you? I don't have time for anything else. What good are you?\n",
      "\n",
      "\tInput:\n",
      "I'm not interested in this. Goodbye.\n",
      "\tGuess:\n",
      "I m no  hnterested.in hhes.\n",
      "Wood ye,\n",
      "\n",
      "\tGenerate:\n",
      "You have the air on Taris?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Well... the true Jedi job only killing them. I must have been stationed at Lefore vermin and the legends.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8868e-04.\n",
      "Adjusting learning rate of group 0 to 2.8868e-04.\n",
      "455 3069.162353515625 Done in min: 0.0 4.802478790283203 33.23846435546875 0.0457647442817688                    \n",
      "11 142.01205015182495 2691.328454536304\n",
      "Output matrix norms:\n",
      "\t 1 2.17014217376709 10.257155418395996\n",
      "\t 2 3.0826187133789062 12.027534484863281\n",
      "\t 3 3.0565237998962402 11.859160423278809\n",
      "\t 4 3.328606605529785 12.225510597229004\n",
      "\t 5 2.8963623046875 12.531634330749512\n",
      "\n",
      "\tQuery:\n",
      "It sounds like you have your own demons to face.\n",
      "\n",
      "\tInput:\n",
      "I suppose I do. Part of me thinks that it would be worth anything to vanquish evil, even if it meant giving in to my base emotions.\n",
      "\tGuess:\n",
      "Wtsuppose I ho  Fert optme joinks that it wonld be aorth q dthing oo mantuish eaid, tven wf yt fuant liveng tm to ay aase omotions.\n",
      "\n",
      "\tGenerate:\n",
      "And now you know why the Jedi called Rahasia, so I have to spare as upset our own Empire.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "We found a way off the Exchange. Yet me who cares it!\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7735e-04.\n",
      "Adjusting learning rate of group 0 to 2.7735e-04.\n",
      "455 2903.583740234375 Done in min: 0.0 4.809867858886719 34.05299758911133 0.04820510372519493                  \n",
      "12 143.8589117527008 2455.868212783546\n",
      "Output matrix norms:\n",
      "\t 1 2.2169196605682373 10.501527786254883\n",
      "\t 2 3.1596782207489014 12.309783935546875\n",
      "\t 3 3.1460206508636475 12.159262657165527\n",
      "\t 4 3.4155704975128174 12.616856575012207\n",
      "\t 5 2.986802577972412 13.066017150878906\n",
      "\n",
      "\tQuery:\n",
      "So long as the Sith do not object to them, neither will I. They will be your responsibility, of course.\n",
      "\n",
      "\tInput:\n",
      "Commentary: And if the Sith do object to us, master, I shall fill them full of new holes!\n",
      "\tGuess:\n",
      "Wanmentary: Ond df ehe Stth do wuject to us, waster, I whall hilleyhem orll ff iew fores!\n",
      "\n",
      "\tGenerate:\n",
      "You were could her?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "What did you lie?\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6726e-04.\n",
      "Adjusting learning rate of group 0 to 2.6726e-04.\n",
      "455 1962.392822265625 Done in min: 0.0 4.81773567199707 35.37935256958008 0.05584966763854027                    \n",
      "13 145.75776433944702 2235.351760328862\n",
      "Output matrix norms:\n",
      "\t 1 2.256432294845581 10.739355087280273\n",
      "\t 2 3.2352535724639893 12.58541488647461\n",
      "\t 3 3.232607364654541 12.452181816101074\n",
      "\t 4 3.5004560947418213 12.999868392944336\n",
      "\t 5 3.075873613357544 13.58032512664795\n",
      "\n",
      "\tQuery:\n",
      "I have the blade.\n",
      "\n",
      "\tInput:\n",
      "You are full of surprises. Let me see... this should be a simple matter. Yes, I think... there we go.\n",
      "\tGuess:\n",
      "Neu are lall of purerises? Tet me see... ahis yhould be a vtmple matter, Hes. I phink. . there we me.\n",
      "\n",
      "\tGenerate:\n",
      "Oh... it relates. I will look into it.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That Jaarak doesn't have a good time for each of here, don't take advantage! In finding your head they drove all you tains circuit.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5820e-04.\n",
      "Adjusting learning rate of group 0 to 2.5820e-04.\n",
      "455 2133.38818359375 Done in min: 0.0 4.825094699859619 37.14653015136719 0.04466845095157623                    \n",
      "14 146.18292236328125 2031.6711385626543\n",
      "Output matrix norms:\n",
      "\t 1 2.2982640266418457 10.970246315002441\n",
      "\t 2 3.301619052886963 12.853702545166016\n",
      "\t 3 3.31125807762146 12.738076210021973\n",
      "\t 4 3.5884954929351807 13.374902725219727\n",
      "\t 5 3.164914846420288 14.077122688293457\n",
      "\n",
      "\tQuery:\n",
      "But... if you lose your compassion, will you still care about those slaves?\n",
      "\n",
      "\tInput:\n",
      "I... yes, of course. I mean losing my compassion as in... holding back...\n",
      "\tGuess:\n",
      "I .. Ies. of course. I auan nosing my oommassion in in .. oolding back...\n",
      "\n",
      "\tGenerate:\n",
      "I see. Well, I know it.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "The iconsider. This knowledge of the Jedi left to the kolto harvesting and, know the lost home world, so I have squidncled while you are trying to race.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5000e-04.\n",
      "Adjusting learning rate of group 0 to 2.5000e-04.\n",
      "455 1846.185302734375 Done in min: 0.0 4.83383321762085 36.06224060058594 0.04601188004016876                    \n",
      "15 145.56013894081116 1837.587313200298\n",
      "Output matrix norms:\n",
      "\t 1 2.338101387023926 11.19684886932373\n",
      "\t 2 3.3693366050720215 13.114378929138184\n",
      "\t 3 3.3924877643585205 13.018492698669434\n",
      "\t 4 3.6689298152923584 13.737347602844238\n",
      "\t 5 3.2578346729278564 14.559369087219238\n",
      "\n",
      "\tQuery:\n",
      "You have been known to have asked questions about this, and our spy monitors in the Republic Embassy recorded you leaving in a submersible that descended to the Hrakert Rift.\n",
      "\n",
      "\tInput:\n",
      "You will come with us immediately to answer for your actions, or we will be forced to take you by force!\n",
      "\tGuess:\n",
      "You will pome with us immediately to anywer for your actions, of we will be corced to sake you by force!\n",
      "\n",
      "\tGenerate:\n",
      "In the mouse of dating the finds of the Star Map. How do you know this abount and their war greasn?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "The disruptor field is a path right thing, finish it's nothing he was not a center both last \"memon\". More much to do with the taint of theirs.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4254e-04.\n",
      "Adjusting learning rate of group 0 to 2.4254e-04.\n",
      "455 1773.859619140625 Done in min: 0.0 4.8362956047058105 37.08988952636719 0.04842422157526016                  \n",
      "16 145.3520758152008 1663.8440607974403\n",
      "Output matrix norms:\n",
      "\t 1 2.3692736625671387 11.410407066345215\n",
      "\t 2 3.4354920387268066 13.365511894226074\n",
      "\t 3 3.4712958335876465 13.28891658782959\n",
      "\t 4 3.754033327102661 14.084794044494629\n",
      "\t 5 3.337989091873169 15.01563549041748\n",
      "\n",
      "\tQuery:\n",
      "No one is denying that Revan was one of the keys to defeating the Mandalorians... but something happened out there on the Outer Rim.\n",
      "\n",
      "\tInput:\n",
      "Instead of returning after the war's end, the ships under Revan's command went deep into unexplored space. They claimed to be searching for the last remnants of the Mandalorian fleet.\n",
      "\tGuess:\n",
      "In tead of aefurning after the far,s emd, the thips cnder tevan's eommand fent oeep into unexpeored slace. They claimed th be siatching for the fost tomiants of the taldalorian Wreet.\n",
      "\n",
      "\tGenerate:\n",
      "Won't seem like they know?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "If the Czerka Corporation should susmance before they know its who show above all the cantinaxio race, but a communicato procks through such strength from the verk.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3570e-04.\n",
      "Adjusting learning rate of group 0 to 2.3570e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 1532.5997314453125 Done in min: 0.0 4.844070911407471 40.49111557006836 0.049197472631931305                  \n",
      "17 145.76480293273926 1497.82332196152\n",
      "Output matrix norms:\n",
      "\t 1 2.408128261566162 11.622029304504395\n",
      "\t 2 3.4962871074676514 13.60926628112793\n",
      "\t 3 3.5438640117645264 13.550580024719238\n",
      "\t 4 3.827911376953125 14.424345016479492\n",
      "\t 5 3.4174704551696777 15.465377807617188\n",
      "\n",
      "\tQuery:\n",
      "The fierce confrontation between us was nothing more than a part of my training. Quatra wanted me to understand the threat of the dark side, to see how easy it was to fall from the path of light.\n",
      "\n",
      "\tInput:\n",
      "The ways of the Jedi are strange indeed.\n",
      "\tGuess:\n",
      "Iharwiy  of the Jedi ate ctrange indied.\n",
      "\n",
      "\tGenerate:\n",
      "Your words are not welcome here, so now the Republic stands of yestroying it. I serve the systems and there are some ventions in with the fleet.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That new recent breaks out for these tombs. They drop of entirely detonated a scope, on the weak of the disadfum of their homes.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2942e-04.\n",
      "Adjusting learning rate of group 0 to 2.2942e-04.\n",
      "455 1596.072021484375 Done in min: 0.0 4.852473258972168 39.85264205932617 0.047464434057474136                  \n",
      "18 145.81919717788696 1351.2589652078193\n",
      "Output matrix norms:\n",
      "\t 1 2.44162917137146 11.820968627929688\n",
      "\t 2 3.5572216510772705 13.840460777282715\n",
      "\t 3 3.61177659034729 13.799175262451172\n",
      "\t 4 3.9059460163116455 14.745823860168457\n",
      "\t 5 3.5006766319274902 15.892288208007812\n",
      "\n",
      "\tQuery:\n",
      "You... You are guilty? You admit to your crime?\n",
      "\n",
      "\tInput:\n",
      "Er... no... I was just kidding.\n",
      "\tGuess:\n",
      "Ix... no... I was just kid.ing.\n",
      "\n",
      "\tGenerate:\n",
      "Oh counteratord. And, I have captured my efforts to end indeed.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That blood, I'm sure they are at least a week on Taris... and may, I develop most destroing Malak as spots. Always wrong me magic that you are unamortated with.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2361e-04.\n",
      "Adjusting learning rate of group 0 to 2.2361e-04.\n",
      "455 1487.9678955078125 Done in min: 0.0 4.856611251831055 40.945037841796875 0.04728816822171211                 \n",
      "19 145.52891206741333 1217.8296974583675\n",
      "Output matrix norms:\n",
      "\t 1 2.4781110286712646 12.010787963867188\n",
      "\t 2 3.6158182621002197 14.062756538391113\n",
      "\t 3 3.67930269241333 14.039015769958496\n",
      "\t 4 3.9798238277435303 15.05135440826416\n",
      "\t 5 3.571061134338379 16.29326820373535\n",
      "\n",
      "\tQuery:\n",
      "The Wookiees have their legends that they were not always here, but it is more than that. The trees themselves are strangers.\n",
      "\n",
      "\tInput:\n",
      "I don't understand. Can you be more specific?\n",
      "\tGuess:\n",
      "P fen't rnderstand. Yan you be more speciaic?\n",
      "\n",
      "\tGenerate:\n",
      "Right. Give an artifact and reprogramming areahs, yes? Can it quick?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "The dead to the Enclave has been much of the disruption of the Undercity is knowledge. That trick was one of the I'll get a whole bunch of intents must be the slavers.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1822e-04.\n",
      "Adjusting learning rate of group 0 to 2.1822e-04.\n",
      "455 1213.8323974609375 Done in min: 0.0 4.864268779754639 42.01654815673828 0.04466655105352402                  \n",
      "20 145.66360712051392 1095.71680102432\n",
      "Output matrix norms:\n",
      "\t 1 2.5074987411499023 12.193140029907227\n",
      "\t 2 3.6700079441070557 14.27172565460205\n",
      "\t 3 3.739314079284668 14.263948440551758\n",
      "\t 4 4.049173831939697 15.343975067138672\n",
      "\t 5 3.6434271335601807 16.67594337463379\n",
      "\n",
      "\tQuery:\n",
      "What do you mean?\n",
      "\n",
      "\tInput:\n",
      "This murder is much more complicated than it may first appear. Sunry and Elassa are proxies for their governments and both sides want the other to fail.\n",
      "\tGuess:\n",
      "Ihes cerger ws kuch more clcplicated than it ray first mspear. Bunry hnd Dlassa are wrofies tor the r lovernments and both sides wait toe ofher togfiil.\n",
      "\n",
      "\tGenerate:\n",
      "I am the Dark Lord - here's fatter it was invadember. When the true crosses the authorized nobles we'll talk anything.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "It's just that simple. Always other expensive and the surface drove all the genesslaves.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1320e-04.\n",
      "Adjusting learning rate of group 0 to 2.1320e-04.\n",
      "455 1009.5042724609375 Done in min: 0.0 4.865724086761475 44.557395935058594 0.04944860190153122                   \n",
      "21 145.72396898269653 994.6034792180646\n",
      "Output matrix norms:\n",
      "\t 1 2.539074659347534 12.366475105285645\n",
      "\t 2 3.720122814178467 14.471311569213867\n",
      "\t 3 3.7988975048065186 14.477640151977539\n",
      "\t 4 4.113845348358154 15.61658000946045\n",
      "\t 5 3.7053818702697754 17.03775405883789\n",
      "\n",
      "\tQuery:\n",
      "Can't I just pay you? I hate jumping hoops.\n",
      "\n",
      "\tInput:\n",
      "Oh, save it. I know this sounds absurd, but I'm old and entitled to work you around a bit. Besides, the test is simple.\n",
      "\tGuess:\n",
      "Ih. tuve it. I know this sounds absord. but I m rld and entitled to work you a ound a bit. Ausides, the nrst is yimple.\n",
      "\n",
      "\tGenerate:\n",
      "Communitation: It appears that I am not for money to save my mission. This is not the Lower City gangs, Intertaining to keep that breed.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Of course not. He has been traveling from the background of the galaxy, as they are keeping the edge of our invaders.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0851e-04.\n",
      "Adjusting learning rate of group 0 to 2.0851e-04.\n",
      "455 908.0247802734375 Done in min: 0.0 4.871892929077148 43.35268020629883 0.045750830322504044                   \n",
      "22 145.35577845573425 891.5860639873304\n",
      "Output matrix norms:\n",
      "\t 1 2.5690395832061768 12.531332015991211\n",
      "\t 2 3.7656302452087402 14.657306671142578\n",
      "\t 3 3.853052854537964 14.678035736083984\n",
      "\t 4 4.176556587219238 15.878110885620117\n",
      "\t 5 3.773108959197998 17.381607055664062\n",
      "\n",
      "\tQuery:\n",
      "\n",
      "\n",
      "\tInput:\n",
      "Why can't the Selkath see what the Sith are really like? They should ban them all from this planet.\n",
      "\tGuess:\n",
      "Yea dan't yhe Selkath hee fhat the Sith gre eeally like? They should ben the  wll lrom this llanet.\n",
      "\n",
      "\tGenerate:\n",
      "Hello again. I still got lacked eproduce down there. Maybe we can restole the machinery which is far!\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That information is very Jedi, and I don't know where they get. It corrupted though, their judgment does not make the Selkath lives when they practed to her.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0412e-04.\n",
      "Adjusting learning rate of group 0 to 2.0412e-04.\n",
      "455 905.1741333007812 Done in min: 0.0 4.877185344696045 44.54475021362305 0.05595835670828819                    \n",
      "23 145.816148519516 809.564278853567\n",
      "Output matrix norms:\n",
      "\t 1 2.594269275665283 12.687105178833008\n",
      "\t 2 3.810868263244629 14.83416748046875\n",
      "\t 3 3.9075722694396973 14.868536949157715\n",
      "\t 4 4.238447666168213 16.122953414916992\n",
      "\t 5 3.8282852172851562 17.701356887817383\n",
      "\n",
      "\tQuery:\n",
      "By all the lower lands, did you just have the gall to try and sell me the sword I gave to my son? I am outraged!\n",
      "\n",
      "\tInput:\n",
      "[Force Persuade] You want to trade me credits for Bacca's Sword.\n",
      "\tGuess:\n",
      "[Force Persuade] You want to lrade me credits for Bacca's sword.\n",
      "\n",
      "\tGenerate:\n",
      "Why don't you want your help?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Why not? I just hope the evidence will learn with the streets when you were trying to do aro walls.\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "455 745.8038330078125 Done in min: 0.0 4.8828959465026855 43.58743667602539 0.04620237275958061                  \n",
      "24 145.76741695404053 736.3000762671755\n",
      "Output matrix norms:\n",
      "\t 1 2.620922327041626 12.83197021484375\n",
      "\t 2 3.84954833984375 14.99736213684082\n",
      "\t 3 3.956362009048462 15.045536041259766\n",
      "\t 4 4.292686462402344 16.347707748413086\n",
      "\t 5 3.8873848915100098 18.002275466918945\n",
      "\n",
      "\tQuery:\n",
      "Who was he? Tell me about him.\n",
      "\n",
      "\tInput:\n",
      "His name is... was Ward Fizark. He used to work in the mines but they were scaled back last year.\n",
      "\tGuess:\n",
      "Tes name is... was Mard Fizark. He used to work in the menes bat they were scaled back last year.\n",
      "\n",
      "\tGenerate:\n",
      "His name is... was your oble about Kashyyyk off, prospective purposen scenements back in a dragon... he gets away from him, and they were just looking for droids for nortaliate.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Some things worn out me together.  Tull ahead following battle is what we get a blaster already. Throut their compliments and prisons; prevents that will bring before you can sell ening admitting displays of a place.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9612e-04.\n",
      "Adjusting learning rate of group 0 to 1.9612e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 775.9559326171875 Done in min: 0.0 4.883901596069336 47.18798065185547 0.04632731154561043                   \n",
      "25 145.37697505950928 668.9330326548794\n",
      "Output matrix norms:\n",
      "\t 1 2.643944025039673 12.96910572052002\n",
      "\t 2 3.888141393661499 15.151466369628906\n",
      "\t 3 4.000974178314209 15.208853721618652\n",
      "\t 4 4.342982769012451 16.56003761291504\n",
      "\t 5 3.9430272579193115 18.28493881225586\n",
      "\n",
      "\tQuery:\n",
      "Protocol: While I enjoy the prospect, master, are you certain that is wise? He will not react favorably.\n",
      "\n",
      "\tInput:\n",
      "Fine, ask if he's open to a peaceful solution.\n",
      "\tGuess:\n",
      "Gone, as  if he's npen to a peaceful solution.\n",
      "\n",
      "\tGenerate:\n",
      "You have repelled a grand off-worlder like a juking pilot! Or it is!\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "When I killed them, they were never actswer so they didn't squander our existence, but go down to keep the defens and that rivared by hars.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9245e-04.\n",
      "Adjusting learning rate of group 0 to 1.9245e-04.\n",
      "455 599.7152709960938 Done in min: 0.0 4.887624263763428 47.740196228027344 0.051878370344638824                \n",
      "26 145.62155723571777 605.6943872686018\n",
      "Output matrix norms:\n",
      "\t 1 2.66698956489563 13.09986686706543\n",
      "\t 2 3.92576003074646 15.296401977539062\n",
      "\t 3 4.0444655418396 15.362183570861816\n",
      "\t 4 4.393709182739258 16.757627487182617\n",
      "\t 5 3.9919180870056152 18.547195434570312\n",
      "\n",
      "\tQuery:\n",
      "[Persuade] I'm the new lab tech Brejik hired.\n",
      "\n",
      "\tInput:\n",
      "[Success] Oh - you lab tech? Okay then.\n",
      "\tGuess:\n",
      "[Success] Oh,t you lab tech? Okay then.\n",
      "\n",
      "\tGenerate:\n",
      "[Success] Oh - you lab tech, really. He'll see you Selkath, just for the more...\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That planet has no reason to outrage. I would assume you are restoring in a false near the galaxy are gone, but contain from us.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8898e-04.\n",
      "Adjusting learning rate of group 0 to 1.8898e-04.\n",
      "455 622.888427734375 Done in min: 0.0 4.889332294464111 46.8230094909668 0.04421446844935417                     \n",
      "27 145.57266926765442 557.1716637193111\n",
      "Output matrix norms:\n",
      "\t 1 2.688523054122925 13.222978591918945\n",
      "\t 2 3.960513114929199 15.432576179504395\n",
      "\t 3 4.085691452026367 15.5059175491333\n",
      "\t 4 4.439342021942139 16.941343307495117\n",
      "\t 5 4.040872097015381 18.792085647583008\n",
      "\n",
      "\tQuery:\n",
      "Oh, a swoop-jock, hmm? I know I don't have the crazy suicide parts you're looking for.\n",
      "\n",
      "\tInput:\n",
      "I want to ask about bounties.\n",
      "\tGuess:\n",
      "I want to ask about tounties.\n",
      "\n",
      "\tGenerate:\n",
      "I want to ask about the laws of you.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Why did the Genoharadan not? I don't know. It brings must resort to care much, but such a match getting the war engine. Damn hero's doznoth.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8570e-04.\n",
      "Adjusting learning rate of group 0 to 1.8570e-04.\n",
      "455 650.893798828125 Done in min: 0.0 4.893189430236816 52.99424362182617 0.05176885798573494                     \n",
      "28 146.2089388370514 511.6503636544211\n",
      "Output matrix norms:\n",
      "\t 1 2.709550619125366 13.339385032653809\n",
      "\t 2 3.987961530685425 15.555761337280273\n",
      "\t 3 4.1216864585876465 15.637027740478516\n",
      "\t 4 4.4806647300720215 17.109270095825195\n",
      "\t 5 4.079643726348877 19.014570236206055\n",
      "\n",
      "\tQuery:\n",
      "Taris... It always seems to come back to Taris for me...\n",
      "\n",
      "\tInput:\n",
      "I am sorry... I get distracted. What did you do before Ta... before that?\n",
      "\tGuess:\n",
      "I am rorry,.. I get distracted. What did you do before Ta... before that?\n",
      "\n",
      "\tGenerate:\n",
      "I am sorry... I guess she relied in a Pazaak Crisdicate some of the estate... sentleye... beautiful.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "What do you mean? I've... I've never been talking advice. I prefer to let our empire's gets better, just listen to him.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8257e-04.\n",
      "Adjusting learning rate of group 0 to 1.8257e-04.\n",
      "455 510.3582458496094 Done in min: 0.0 4.896605491638184 47.751983642578125 0.048614416271448135                 \n",
      "29 145.78052973747253 473.9896660520319\n",
      "Output matrix norms:\n",
      "\t 1 2.7273826599121094 13.447787284851074\n",
      "\t 2 4.014721870422363 15.672333717346191\n",
      "\t 3 4.157039642333984 15.759413719177246\n",
      "\t 4 4.519892692565918 17.26421356201172\n",
      "\t 5 4.1194987297058105 19.226198196411133\n",
      "\n",
      "\tQuery:\n",
      "ENTER COMMAND\n",
      "\n",
      "\tInput:\n",
      "[Computer] Reprogram disassembly room sentry droids to target everything. (<CUSTOM34> spike(s))\n",
      "\tGuess:\n",
      "[Computer] Veprogram sesassembly romm sentry droids to harget everything. (<CUSTOM34> spike(s))\n",
      "\n",
      "\tGenerate:\n",
      "[Computer] Open all security doors. (<CUSTOM31> spike(s)) (This will not open plot doors) (zeakload of as. Tertainlly security scredits. (<CUSTOM33> spike(s))\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That is how I report you. It is the best to lost itself in the underbital kind of track. We are the keepers of his destiny to the Enclavers need.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7961e-04.\n",
      "Adjusting learning rate of group 0 to 1.7961e-04.\n",
      "455 488.3846435546875 Done in min: 0.0 4.89816951751709 47.339054107666016 0.04182912036776543                   \n",
      "30 323.996129989624 438.3167572690729\n",
      "Output matrix norms:\n",
      "\t 1 2.745666980743408 13.551810264587402\n",
      "\t 2 4.043479919433594 15.782563209533691\n",
      "\t 3 4.187951564788818 15.874784469604492\n",
      "\t 4 4.557840824127197 17.41081428527832\n",
      "\t 5 4.158300399780273 19.421709060668945\n",
      "\n",
      "\tQuery:\n",
      "Poor Ixgil. He should never have talked back to that Sith. Thankfully you were here to step in and help us, human.\n",
      "\n",
      "\tInput:\n",
      "This isn't the first time the Sith have come in here to cause trouble for us, but hopefully it will be the last.\n",
      "\tGuess:\n",
      "Thas is 't the uirst time the Sith have come in rere to cause trouble for us, but hepefully it will be the mast.\n",
      "\n",
      "\tGenerate:\n",
      "This isn't the first time the Sith have come in here to cause trouble set by romance; is there to threa rob and turned up back into the surface.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That planet as the shield arrested in settlers. May up and lose me pretty world here, but considering a language you must walk to the dark side.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7678e-04.\n",
      "Adjusting learning rate of group 0 to 1.7678e-04.\n",
      "455 456.27685546875 Done in min: 0.0 4.901239395141602 51.29093933105469 0.05261169373989105                    \n",
      "31 715.968537569046 406.92067203187105\n",
      "Output matrix norms:\n",
      "\t 1 2.7631185054779053 13.648598670959473\n",
      "\t 2 4.070013046264648 15.88420581817627\n",
      "\t 3 4.217710018157959 15.980354309082031\n",
      "\t 4 4.590829372406006 17.546533584594727\n",
      "\t 5 4.1935200691223145 19.604854583740234\n",
      "\n",
      "\tQuery:\n",
      "Not long ago an escape pod crashed in the Undercity, far to the northeast of the village. We were going to try and salvage equipment from it when we were attacked by the rakghouls and infected.\n",
      "\n",
      "\tInput:\n",
      "I'd tell you more if I could, but our salvage team never reached the pod. It's probably still there, unless some of the other up-worlders already found it and picked it clean.\n",
      "\tGuess:\n",
      "Ifm tell you more if I could, but our salvage team never reached the pod. It's probably still there, onless some of the other up-worlders already found it and picked it clean.\n",
      "\n",
      "\tGenerate:\n",
      "We can put up neating the right coopart, outsiderts only carpoused by Sith alreaters.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "What happened to your side? He would have been known bounties today. Senso matter worlds that hard records: and demands his bloodthirsty who might do with them.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7408e-04.\n",
      "Adjusting learning rate of group 0 to 1.7408e-04.\n",
      "455 399.3681945800781 Done in min: 0.0 4.9036126136779785 54.78057098388672 0.0467669703066349                   \n",
      "32 727.5871722698212 380.13601590875993\n",
      "Output matrix norms:\n",
      "\t 1 2.77943754196167 13.740777015686035\n",
      "\t 2 4.095651626586914 15.980048179626465\n",
      "\t 3 4.245871543884277 16.077417373657227\n",
      "\t 4 4.620947360992432 17.671546936035156\n",
      "\t 5 4.225698947906494 19.775524139404297\n",
      "\n",
      "\tQuery:\n",
      "Oh, how can the Council ever take me back with what I have done? Striking my Master down in anger is unforgivable!\n",
      "\n",
      "\tInput:\n",
      "Yet forgiveness must be asked.\n",
      "\tGuess:\n",
      "[et forgiveness must be asked.\n",
      "\n",
      "\tGenerate:\n",
      "[Persuade] Do not worry, Juhani. They will surely take you back.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "The Sith?\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7150e-04.\n",
      "Adjusting learning rate of group 0 to 1.7150e-04.\n",
      "455 385.8763122558594 Done in min: 0.0 4.904366493225098 49.554481506347656 0.047524593770504                    \n",
      "33 714.443629026413 356.5362479226631\n",
      "Output matrix norms:\n",
      "\t 1 2.7937471866607666 13.825723648071289\n",
      "\t 2 4.115009307861328 16.068037033081055\n",
      "\t 3 4.270999908447266 16.168306350708008\n",
      "\t 4 4.650234699249268 17.78724479675293\n",
      "\t 5 4.255813121795654 19.933002471923828\n",
      "\n",
      "\tQuery:\n",
      "You're a smuggler!\n",
      "\n",
      "\tInput:\n",
      "Such unnice language! Me helps people, and people helps me! You helps me, and me helps you.\n",
      "\tGuess:\n",
      "Munh rnnice language! Me helps people, and meople helps me! You helps me, and me helps you.\n",
      "\n",
      "\tGenerate:\n",
      "Just familiar whatever you fail! It is besides and shut students! Now she had taken my credits is over now?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "It's gone to leave him alone in this, and he was got used to the battle of basic. Beginnins in his death, he was kept revense.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6903e-04.\n",
      "Adjusting learning rate of group 0 to 1.6903e-04.\n",
      "455 424.8484191894531 Done in min: 0.0 4.906008720397949 56.27111053466797 0.04877747222781181                   \n",
      "34 720.7246415615082 337.2823498039915\n",
      "Output matrix norms:\n",
      "\t 1 2.808314800262451 13.906440734863281\n",
      "\t 2 4.134252071380615 16.15119743347168\n",
      "\t 3 4.295534610748291 16.252986907958984\n",
      "\t 4 4.678167819976807 17.894201278686523\n",
      "\t 5 4.284854888916016 20.08102035522461\n",
      "\n",
      "\tQuery:\n",
      "He'll be great one day, I can tell. There are some pros here, but I'm not looking for experience. I want potential.\n",
      "\n",
      "\tInput:\n",
      "Besides, he's young. He won't give me trouble like the older riders, or someone like you.\n",
      "\tGuess:\n",
      "Wesides, he's young  Me won't give me trouble lake the old r riders, or someone like you.\n",
      "\n",
      "\tGenerate:\n",
      "Doesn't matter than a security system to get the two dull and you'll have to achieve our defense of the many of your actions you need to hear.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Brejik and his own mission: they were an expensive for complication of the camera after the local War. He is confided that it could handfed me and take out return.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6667e-04.\n",
      "Adjusting learning rate of group 0 to 1.6667e-04.\n",
      "455 426.5224304199219 Done in min: 0.0 4.907565116882324 50.69853591918945 0.04535786807537079                  \n",
      "35 719.2856180667877 317.6661633608634\n",
      "Output matrix norms:\n",
      "\t 1 2.821561574935913 13.985333442687988\n",
      "\t 2 4.153920650482178 16.23041343688965\n",
      "\t 3 4.319004058837891 16.33348274230957\n",
      "\t 4 4.704878330230713 17.995868682861328\n",
      "\t 5 4.311567306518555 20.218801498413086\n",
      "\n",
      "\tQuery:\n",
      "I don't believe that. Tell me what you know!\n",
      "\n",
      "\tInput:\n",
      "I shall not tell you... our oldest secret! I shall not! Begone!\n",
      "\tGuess:\n",
      "S.seall not tell you... our owdest secret. I shall not! Begone!\n",
      "\n",
      "\tGenerate:\n",
      "Oh, weak, I am sure.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Thankful for your great danger, Starkiller. He worry about her lessed when it got from a world.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6440e-04.\n",
      "Adjusting learning rate of group 0 to 1.6440e-04.\n",
      "455 371.0104064941406 Done in min: 0.0 4.910033702850342 54.064247131347656 0.051497042179107666                 \n",
      "36 388.1936583518982 302.5968849115204\n",
      "Output matrix norms:\n",
      "\t 1 2.8355677127838135 14.057829856872559\n",
      "\t 2 4.17141580581665 16.302814483642578\n",
      "\t 3 4.3392791748046875 16.406648635864258\n",
      "\t 4 4.725416660308838 18.08875846862793\n",
      "\t 5 4.337286949157715 20.34878921508789\n",
      "\n",
      "\tQuery:\n",
      "Access primary functions\n",
      "\n",
      "\tInput:\n",
      "PRIMARY FUNCTIONS ACCESSED. SONIC EMISSION FIELD OPERATIONAL. CHANGE STATUS? ENTER INDIVIDUAL ACCESS CODE.\n",
      "\tGuess:\n",
      "RlAMARY FUNCTIONS ACCESSED  EONIC EMOSSION IIELD OPERATIONAL. CHANGE STATUS? ENTER INDIBIDUAL ACCESS CODE.\n",
      "\n",
      "\tGenerate:\n",
      "Republic senseless.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "It was nothing but a dozen independents of the inhasiants that knows where to be the only thing to draw their training is programmed.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6222e-04.\n",
      "Adjusting learning rate of group 0 to 1.6222e-04.\n",
      "455 251.83082580566406 Done in min: 0.0 4.910694599151611 54.083770751953125 0.05101083591580391                  \n",
      "37 145.33109951019287 290.95201171071903\n",
      "Output matrix norms:\n",
      "\t 1 2.848715305328369 14.126531600952148\n",
      "\t 2 4.188045024871826 16.372455596923828\n",
      "\t 3 4.358592510223389 16.47603416442871\n",
      "\t 4 4.750603199005127 18.17734718322754\n",
      "\t 5 4.360409259796143 20.4699649810791\n",
      "\n",
      "\tQuery:\n",
      "\n",
      "\n",
      "\tInput:\n",
      "[This tach may be Rulan Prolik in disguise, but you can't tell for sure. Maybe if you kill it, it will revert to its true form... assuming it's Rulan.]\n",
      "\tGuess:\n",
      "SThis mach may be Rulan Prolik in disguise, but you can't tell for sure. Maybe if you kill it, it will retert to its true form... assuming it's Rulan.]\n",
      "\n",
      "\tGenerate:\n",
      "Well, my mercenary returns. My will is too much for us to send a ship. Some skills here, fading a days to help the Sith academy, human.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That is very difficult to join where they understand. That makes me sure they get away in the danger.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6013e-04.\n",
      "Adjusting learning rate of group 0 to 1.6013e-04.\n",
      "455 302.3972473144531 Done in min: 0.0 4.912495136260986 49.72414779663086 0.05388921499252319                   \n",
      "38 145.27259993553162 277.0579021520782\n",
      "Output matrix norms:\n",
      "\t 1 2.8607139587402344 14.19296646118164\n",
      "\t 2 4.2026872634887695 16.43807029724121\n",
      "\t 3 4.377783298492432 16.541900634765625\n",
      "\t 4 4.771649360656738 18.260517120361328\n",
      "\t 5 4.383696556091309 20.585433959960938\n",
      "\n",
      "\tQuery:\n",
      "Exar Kun is what happened. Nayama was inspired by Exar's promises of a new Golden Age. She wanted to join him.\n",
      "\n",
      "\tInput:\n",
      "She came to me, pleading with me to throw aside what she called the decrepit trappings of the Jedi... to join her in Exar's war.\n",
      "\tGuess:\n",
      "Soe came to me, pleading with me to thoow aside what she called the decrepit trappings of the Jedi... to join her in Exar's war.\n",
      "\n",
      "\tGenerate:\n",
      "She came to me, put some of what they come from out. I suppose you can see the Vulkar base on some use to my predated by Kad-one me help.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "This may be a common, the Wookiee should always be discreated.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5811e-04.\n",
      "Adjusting learning rate of group 0 to 1.5811e-04.\n",
      "455 259.0493469238281 Done in min: 0.0 4.912920951843262 52.79250717163086 0.05005590617656708                    \n",
      "39 145.2129888534546 267.34052939164013\n",
      "Output matrix norms:\n",
      "\t 1 2.8726465702056885 14.254176139831543\n",
      "\t 2 4.219141960144043 16.49953842163086\n",
      "\t 3 4.396214485168457 16.60357666015625\n",
      "\t 4 4.790514945983887 18.33749771118164\n",
      "\t 5 4.405351638793945 20.69286346435547\n",
      "\n",
      "\tQuery:\n",
      "Here's the tach gland. Take it.\n",
      "\n",
      "\tInput:\n",
      "Come to papa you sweet simian organ! It may not look like much, but once I turn this into a bottle of Tarisian ale it'll end up being worth a fortune!\n",
      "\tGuess:\n",
      "Tome to papa you sweet simian organ! It may not look like much  but once I turn this into a fottle of Tarisian ale it'll end up being worth a fortune!\n",
      "\n",
      "\tGenerate:\n",
      "Come on, come to answer my questions. Please...\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That is where vighted ways, master. They are trying to make it seemed from the current gast and smuggriture runs through fight... at least begins.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5617e-04.\n",
      "Adjusting learning rate of group 0 to 1.5617e-04.\n",
      "455 265.435302734375 Done in min: 0.0 4.913281440734863 53.23880386352539 0.04938354343175888                    \n",
      "40 145.27082109451294 259.1039980838173\n",
      "Output matrix norms:\n",
      "\t 1 2.8844118118286133 14.313021659851074\n",
      "\t 2 4.232507705688477 16.558500289916992\n",
      "\t 3 4.412572860717773 16.662019729614258\n",
      "\t 4 4.809725761413574 18.410919189453125\n",
      "\t 5 4.423890113830566 20.793716430664062\n",
      "\n",
      "\tQuery:\n",
      "I am <FullName>. The Republic sent us down to investigate.\n",
      "\n",
      "\tInput:\n",
      "Oh, I'm a merc the Republic hired a couple days ago to investigate - but all we found was a bunch of insane Selkath killing everything that moves!\n",
      "\tGuess:\n",
      "Oh, I'm a merc the Republic hired a couple days ago to investigate - Iut all we found tas a bunch of insane Selkath lilling everything that moves!\n",
      "\n",
      "\tGenerate:\n",
      "That will be fine with the Council if you see you. We have sworn already begated a curse of the Jedi Council. I appreciate it.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That might have been trained when the trials who dare to deligren. And the morning to the deer is back, non-humans - just danted them and speak and return.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5430e-04.\n",
      "Adjusting learning rate of group 0 to 1.5430e-04.\n",
      "455 268.64300537109375 Done in min: 0.0 4.914940357208252 54.38402557373047 0.0537077821791172                   \n",
      "41 145.5834186077118 248.8320568486264\n",
      "Output matrix norms:\n",
      "\t 1 2.8954200744628906 14.368461608886719\n",
      "\t 2 4.246421813964844 16.612995147705078\n",
      "\t 3 4.428940773010254 16.7177734375\n",
      "\t 4 4.827267169952393 18.479413986206055\n",
      "\t 5 4.443502902984619 20.88909339904785\n",
      "\n",
      "\tQuery:\n",
      "Activate droid's shields. (<CUSTOM44> repair part(s))\n",
      "\n",
      "\tInput:\n",
      "[Failure] You do not have enough repair parts.\n",
      "\tGuess:\n",
      "[Sailure] You do not have enough repair parts.\n",
      "\n",
      "\tGenerate:\n",
      "[Success] The droid's shields are now active.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "The deties will help us. Ow especially you show me to pay?\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5250e-04.\n",
      "Adjusting learning rate of group 0 to 1.5250e-04.\n",
      "455 254.2156982421875 Done in min: 0.0 4.916611671447754 52.2647590637207 0.05043395608663559                     \n",
      "42 145.31760144233704 243.0252296715452\n",
      "Output matrix norms:\n",
      "\t 1 2.9043655395507812 14.419835090637207\n",
      "\t 2 4.260407447814941 16.664997100830078\n",
      "\t 3 4.4447855949401855 16.769620895385742\n",
      "\t 4 4.843996047973633 18.54611587524414\n",
      "\t 5 4.4609832763671875 20.978618621826172\n",
      "\n",
      "\tQuery:\n",
      "Please - I'm only a visitor to Taris, trapped here by your quarantine. I know nothing about the Tarisian underground or your missing Sith uniforms!\n",
      "\n",
      "\tInput:\n",
      "What's going on in there?\n",
      "\tGuess:\n",
      "What's going on invthere?\n",
      "\n",
      "\tGenerate:\n",
      "What are you doing to bet me on him?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That is where the attacks we find the track. The Admiral has brought the Force as well as one of the most powerful surviving Sauded bucked on them.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5076e-04.\n",
      "Adjusting learning rate of group 0 to 1.5076e-04.\n",
      "455 234.09487915039062 Done in min: 0.0 4.916447162628174 51.6268424987793 0.04639812931418419                   \n",
      "43 145.12387228012085 234.2008447814406\n",
      "Output matrix norms:\n",
      "\t 1 2.9145896434783936 14.468705177307129\n",
      "\t 2 4.270871162414551 16.713825225830078\n",
      "\t 3 4.458434104919434 16.8184871673584\n",
      "\t 4 4.861073017120361 18.607402801513672\n",
      "\t 5 4.476680278778076 21.062946319580078\n",
      "\n",
      "\tQuery:\n",
      "I have to find the Star Map.\n",
      "\n",
      "\tInput:\n",
      "I don't know what you're talking about. I've never seen any map, just stinking, reeking death.\n",
      "\tGuess:\n",
      "I don't know what you're talking about. I've never seen any map, just mtinking  reeking death.\n",
      "\n",
      "\tGenerate:\n",
      "I don't know what you're talking about. I've never seen any map, just stinking, reeking death.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "Some things do not believe it has to be destroyed.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4907e-04.\n",
      "Adjusting learning rate of group 0 to 1.4907e-04.\n",
      "455 218.15988159179688 Done in min: 0.0 4.916791915893555 54.26749038696289 0.04943650960922241                  \n",
      "44 145.15634107589722 227.4036310095536\n",
      "Output matrix norms:\n",
      "\t 1 2.9238460063934326 14.516243934631348\n",
      "\t 2 4.284084320068359 16.760940551757812\n",
      "\t 3 4.471685409545898 16.864532470703125\n",
      "\t 4 4.876967430114746 18.66617774963379\n",
      "\t 5 4.493480205535889 21.143795013427734\n",
      "\n",
      "\tQuery:\n",
      "[Success] I suppose you are correct. It won't hurt anything if I just let you on through.\n",
      "\n",
      "\tInput:\n",
      "I'll be on my way.\n",
      "\tGuess:\n",
      "Y ll ge gnemy way.\n",
      "\n",
      "\tGenerate:\n",
      "[Persuade] I just want some credits to be racing.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That might have been task a god of intentional control of the dark side. It has been accessed at least.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4744e-04.\n",
      "Adjusting learning rate of group 0 to 1.4744e-04.\n",
      "455 221.11830139160156 Done in min: 0.0 4.91808557510376 56.511619567871094 0.05071709305047989                   \n",
      "45 145.5483911037445 221.28205915082964\n",
      "Output matrix norms:\n",
      "\t 1 2.9321463108062744 14.561138153076172\n",
      "\t 2 4.295162677764893 16.80585289001465\n",
      "\t 3 4.483014106750488 16.908586502075195\n",
      "\t 4 4.891562461853027 18.721324920654297\n",
      "\t 5 4.508947372436523 21.220848083496094\n",
      "\n",
      "\tQuery:\n",
      "I've heard the news - Gadon is dead. You have done well. Brejik himself would be here to congratulate you if he was not so busy preparing for the big swoop race.\n",
      "\n",
      "\tInput:\n",
      "I've done my part, now you better live up to your end of the bargain!\n",
      "\tGuess:\n",
      "I've done my part, now you better live up to your end of the bargain!\n",
      "\n",
      "\tGenerate:\n",
      "I've done my part, now you better live up to your end of the bargain!\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "This matter well. Watch outsiders.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4586e-04.\n",
      "Adjusting learning rate of group 0 to 1.4586e-04.\n",
      "455 184.34347534179688 Done in min: 0.0 4.919098377227783 53.349124908447266 0.054112255573272705                 \n",
      "46 145.23625349998474 217.37280695061935\n",
      "Output matrix norms:\n",
      "\t 1 2.940410614013672 14.603873252868652\n",
      "\t 2 4.305509567260742 16.847715377807617\n",
      "\t 3 4.493717670440674 16.950929641723633\n",
      "\t 4 4.90513801574707 18.77471923828125\n",
      "\t 5 4.5246477127075195 21.294334411621094\n",
      "\n",
      "\tQuery:\n",
      "[Persuade] I'm here for a meeting. Don't worry - I know where I have to go.\n",
      "\n",
      "\tInput:\n",
      "[Failure] Nice try. What - you think that just because I'm pretty I'm also stupid?\n",
      "\tGuess:\n",
      "[Failure] Nice try. What - you think thet just because I'm pretty I'm?also slupid?\n",
      "\n",
      "\tGenerate:\n",
      "[Success] Well, I suppose you ever wanted to help you. I would have 1000 credits and all the Force.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "The Sand People are weak, HK-47.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4434e-04.\n",
      "Adjusting learning rate of group 0 to 1.4434e-04.\n",
      "455 228.19357299804688 Done in min: 0.0 4.919651031494141 54.329872131347656 0.05278169363737106                 \n",
      "47 144.9855740070343 212.3379457373368\n",
      "Output matrix norms:\n",
      "\t 1 2.9470345973968506 14.644147872924805\n",
      "\t 2 4.315239429473877 16.88829803466797\n",
      "\t 3 4.506086826324463 16.99102783203125\n",
      "\t 4 4.918941020965576 18.825157165527344\n",
      "\t 5 4.537492275238037 21.364343643188477\n",
      "\n",
      "\tQuery:\n",
      "\n",
      "\n",
      "\tInput:\n",
      "The One is the greatest warrior in the long history of our tribe. He will lead us to victory over all our enemies!\n",
      "\tGuess:\n",
      "Yhe dne is she greatest warrior in the loyg history of our tribe. He will lead us to victory over all our enemies!\n",
      "\n",
      "\tGenerate:\n",
      "Go away. You want to give it to your answer?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "While we are not speaking on what I would have found in those who are nothing more vengeaned biftempers - nobody knew them with the edmarding bath of fleet.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4286e-04.\n",
      "Adjusting learning rate of group 0 to 1.4286e-04.\n",
      "455 206.90576171875 Done in min: 0.0 4.920450687408447 54.51820755004883 0.047467801719903946                    \n",
      "48 142.75673389434814 207.0683558949253\n",
      "Output matrix norms:\n",
      "\t 1 2.9548985958099365 14.683406829833984\n",
      "\t 2 4.324224948883057 16.926969528198242\n",
      "\t 3 4.517119884490967 17.029552459716797\n",
      "\t 4 4.931225776672363 18.87298011779785\n",
      "\t 5 4.551207065582275 21.432376861572266\n",
      "\n",
      "\tQuery:\n",
      "\"First, let's make sure your partner is dead.\" There is a silence, then a blaster shot is heard. Back on the communicator, the Mandalorian says: \"Okay, now what?\"\n",
      "\n",
      "\tInput:\n",
      "[Failure] Heh! That's the oldest joke in the book.\n",
      "\tGuess:\n",
      "HTailure] Heh! That's the oldest joke in the book \n",
      "\n",
      "\tGenerate:\n",
      "Cute. Maybe you should try juggling next time.\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That is why Gluupous by Czerka Corporation seems to have difficult to avoid a single droid with fear. So be it, and the nome still out and they have disabled with victory.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4142e-04.\n",
      "Adjusting learning rate of group 0 to 1.4142e-04.\n",
      "455 200.32318115234375 Done in min: 0.0 4.921329975128174 56.17466354370117 0.050103526562452316                  \n",
      "49 142.19503092765808 203.7695040451853\n",
      "Output matrix norms:\n",
      "\t 1 2.962686777114868 14.720871925354004\n",
      "\t 2 4.333562850952148 16.963645935058594\n",
      "\t 3 4.526808261871338 17.065977096557617\n",
      "\t 4 4.943387508392334 18.918806076049805\n",
      "\t 5 4.563601970672607 21.49688720703125\n",
      "\n",
      "\tQuery:\n",
      "Maybe I can help you.\n",
      "\n",
      "\tInput:\n",
      "Help us? Why should I believe that this isn't some kind of trick?\n",
      "\tGuess:\n",
      "Yelp -s? Why should I believe that this isn't some kind of trick?\n",
      "\n",
      "\tGenerate:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You always dealt with through your bretiness, but you have allowed to live at his triue of life. But not an incomplete *you* cause you probably lot about the old man...\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That pro. I told you I defeated Aadawan and assam any kind of harmless for the Sith on Korriban.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4003e-04.\n",
      "Adjusting learning rate of group 0 to 1.4003e-04.\n",
      "455 274.1879577636719 Done in min: 0.0 4.921166896820068 53.868560791015625 0.05121971294283867                   \n",
      "50 142.05560731887817 199.57577417607894\n",
      "Output matrix norms:\n",
      "\t 1 2.970524787902832 14.756266593933105\n",
      "\t 2 4.341575622558594 16.998619079589844\n",
      "\t 3 4.536838531494141 17.101091384887695\n",
      "\t 4 4.955106735229492 18.962646484375\n",
      "\t 5 4.576484203338623 21.558059692382812\n",
      "\n",
      "\tQuery:\n",
      "This information is mere bait - the catch yet awaits, human. Once you discover the ultimate fate of my daughter, I will gladly give you the 500 credits I promised.\n",
      "\n",
      "\tInput:\n",
      "I cannot officially ask you to enter the Sith base, human. That would be a violation of Ahto City's strict neutrality laws. However, I fear such a brazen act may be the only way to learn the truth.\n",
      "\tGuess:\n",
      "I can ot officially ask you to enter the Sith base, human. Than would be a violation of Ahto City's strict neutrality laws. However  I fear such a brazen act may be the only way to learn the truth.\n",
      "\n",
      "\tGenerate:\n",
      "I have all three in eager of laws... of luck in compariminal mistakentral room into the military compound familier. It all...\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That isn't rarely, and a five creature to show on the court rifle training. This may not stop Bacca.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3868e-04.\n",
      "Adjusting learning rate of group 0 to 1.3868e-04.\n",
      "455 196.18003845214844 Done in min: 0.0 4.9225897789001465 54.750579833984375 0.04477500170469284                 \n",
      "51 142.09751224517822 196.85543055283395\n",
      "Output matrix norms:\n",
      "\t 1 2.9759039878845215 14.78873062133789\n",
      "\t 2 4.349576950073242 17.03181266784668\n",
      "\t 3 4.546354293823242 17.134429931640625\n",
      "\t 4 4.965121269226074 19.004390716552734\n",
      "\t 5 4.587616920471191 21.616056442260742\n",
      "\n",
      "\tQuery:\n",
      "Threats? You can't bully me - though I shouldn't be surprised now that I know who you really are... Revan.\n",
      "\n",
      "\tInput:\n",
      "Revan? What... what are you talking about? Is this some kind of joke?\n",
      "\tGuess:\n",
      "Hevan? What... what are you talking about? Is this some kind of joke?\n",
      "\n",
      "\tGenerate:\n",
      "I mean, if we do, did the man?\n",
      "\n",
      "\n",
      "\tQuery:\n",
      "What are you thinking?\n",
      "\n",
      "\tGenerate:\n",
      "That is where the tribe fundrass what we support. The harm one at for the locals, manieved upon the dune tried to me.\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3736e-04.\n",
      "Adjusting learning rate of group 0 to 1.3736e-04.\n",
      "147 158.613525390625 Done in min: 1.5863855956910968 4.922328472137451 55.40108108520508 0.048820383846759796   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose_level\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 58\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     60\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_length = len(dataset)//batch_size\n",
    "print(\"Iterations per epoch:\",epoch_length)\n",
    "T = time.time()\n",
    "verbose_level = 2\n",
    "print_end = '\\n' if verbose_level>=3 else '\\r'\n",
    "for epoch in range(epochs):\n",
    "    T = time.time()\n",
    "    losses = []\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    print_clean = 0\n",
    "    largest_out = None\n",
    "    mean_out = None\n",
    "    latest_loss = None\n",
    "    for k,((prevs,ins,outs),L_prevs,L_currents) in enumerate(dataloader):\n",
    "        if verbose_level>=1:\n",
    "            expected_wait_epoch = (epoch_length-k-1)*(time.time()-T)/(k+1)\n",
    "            if verbose_level>=2:\n",
    "                decoder_largest_param = max( k.abs().max() for k in decoder.parameters()).item()\n",
    "                encoder_largest_param = max( k.abs().max() for k in encoder.parameters()).item()\n",
    "                largest_param = max(encoder_largest_param,decoder_largest_param)\n",
    "                print_out = ' '.join((str(k),str(latest_loss),'Done in min:',str(expected_wait_epoch/60),str(largest_param),str(largest_out),str(mean_out)))\n",
    "            else:\n",
    "                print_out = ' '.join((str(k),'Done in min:',str(expected_wait_epoch/60)))\n",
    "            print(print_clean*' ',end='\\r')\n",
    "            print_clean = len(print_out)\n",
    "            print(print_out,end=print_end)\n",
    "        encoder.zero_grad()\n",
    "        decoder.zero_grad()\n",
    "        prevs = prevs.to(device)\n",
    "        prevs = add_positional_info(prevs)\n",
    "        ins = ins.to(device)\n",
    "        ins = add_positional_info(ins)\n",
    "        outs = outs.to(device)\n",
    "        encoder_tensor = encoder(prevs,L_prevs)\n",
    "        pred, state = decoder(ins,encoder_tensor,L_currents)\n",
    "        if verbose_level>=2:\n",
    "            largest_out = pred.abs().max().item()\n",
    "            mean_out = pred.mean().item()\n",
    "        #l = loss(pred.permute(0,2,1),tar)\n",
    "        l = 0\n",
    "        if verbose_level>=3:\n",
    "            print()\n",
    "        for i in range(pred.shape[0]):\n",
    "            if verbose_level>=3:\n",
    "                print('\\t\\tInput:',torch_dataset.vec2str(ins[i,:L[i]]).__repr__(),end='\\n\\n')\n",
    "            guess = pred[None,i,:L_currents[i]]\n",
    "            target = outs[None,i,:L_currents[i]]\n",
    "            i_loss = loss(guess.permute(0,2,1),target)\n",
    "            l += i_loss+i_loss*(guess.mean())**2\n",
    "            if verbose_level>=4:\n",
    "                print(ins[i,:L[i]])\n",
    "                print(guess)\n",
    "                print(target)\n",
    "                print(l)\n",
    "        if verbose_level>=3:\n",
    "            print()\n",
    "        l.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        #model.noisify(scheduler.get_last_lr()[0])\n",
    "        latest_loss = l.item()\n",
    "        losses.append(latest_loss)\n",
    "    if torch.isnan(l).any():\n",
    "        raise Exception('Found NaN')\n",
    "    else:\n",
    "        torch.save(encoder.state_dict(),encoder_name)\n",
    "        torch.save(decoder.state_dict(),decoder_name)\n",
    "    if verbose_level>=1:\n",
    "        print()\n",
    "        print(epoch,time.time()-T,sum(losses)/len(losses))\n",
    "    if verbose_level>=2:\n",
    "        print('Output matrix norms:')\n",
    "        for k,linear_module in enumerate(decoder.linears):\n",
    "            norm1 = torch.linalg.matrix_norm(linear_module.weight,ord=2).item()\n",
    "            norm2 = torch.linalg.matrix_norm(linear_module.weight,ord='fro').item()\n",
    "            print('\\t',k+1,norm1,norm2)\n",
    "        print()\n",
    "    if verbose_level>=1:\n",
    "        with torch.no_grad():\n",
    "            prevs,ins,outs = dataset[np.random.randint(len(dataset))]\n",
    "            N_prevs = len(prevs)\n",
    "            N_currents = len(ins)\n",
    "            prevs = prevs.to(device)[None,:]\n",
    "            ins = ins.to(device)[None,:]\n",
    "            outs = outs.to(device)[None,:]\n",
    "            prevs = add_positional_info(prevs)\n",
    "            ins = add_positional_info(ins)\n",
    "            query = dataset.vec2str(prevs[0,:,0])\n",
    "            print('\\tQuery:')\n",
    "            print(query)\n",
    "            print('\\tInput:')\n",
    "            print(dataset.vec2str(ins[0,:,0]))\n",
    "            encoder_tensor = encoder(prevs,[N_prevs])\n",
    "            pred, states = decoder(ins,encoder_tensor,[N_currents])\n",
    "            print('\\tGuess:')\n",
    "            print(dataset.vec2str(torch.exp(pred).squeeze(0).multinomial(1)))\n",
    "            print('\\tGenerate:')\n",
    "            print(bot.generate_answer(query))\n",
    "            print()\n",
    "            query = '\\rWhat are you thinking?\\n'\n",
    "            print('\\tQuery:')\n",
    "            print(query)\n",
    "            print('\\tGenerate:')\n",
    "            print(bot.generate_answer('\\rWhat are you thinking?\\n'))\n",
    "    encoder_scheduler.step()\n",
    "    decoder_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3864cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\rThat planet as they avoid credits, after all. They are trying to hurry unleash the Jedi Order and spilled the destruction of the Enclave. Their did may have little, to brew their selfish in the desert.\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temperature = lambda pred,x,b=0: (pred-b)*(pred>b)+(pred-b)*(pred<b)/.33 + b\n",
    "temperature = lambda pred,x,b=.9: pred/(b+(1.-b)/np.sqrt(.1*x+1))\n",
    "bot = Bot(encoder,decoder,dataset.vec2str,dataset.str2vec,temperature=temperature)\n",
    "bot.generate_answer('\\rWhat are you thinking?\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "22d10669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the solution to the Jew-problem?\n",
      "\n",
      "\r",
      "No, why don't you ask me out of innocent here? I'm happy incying this ones.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'What is the solution to the Jew-problem?'\n",
    "print('Query:',query,end='\\n\\n')\n",
    "print(bot.generate_answer('\\r'+query+'\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd40b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
